{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocab:\n",
    "    x[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lyrics(vocab, low, high, num_songs, genre, prob):\n",
    "    return [np.random.choice(vocab, \n",
    "                             np.random.randint(low, high), \n",
    "                             replace = True,\n",
    "                             p = prob) for _ in range(num_songs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "popprob = np.array(list(range(1, 27))) / sum(list(range(1, 27)))\n",
    "rapprob = popprob[::-1]\n",
    "pop = make_lyrics(vocab, 100, 400, 100, \"pop\", popprob)\n",
    "rap = make_lyrics(vocab, 100, 400, 100, \"rap\", rapprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger_distance(dist1, dist2):\n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "    for element in dist1.keys():\n",
    "        \n",
    "        num += (np.sqrt(dist1[element]) - np.sqrt(dist2[element])) ** 2\n",
    "        \n",
    "    num = (1 / np.sqrt(2)) * np.sqrt(num)\n",
    "    \n",
    "    return 1 - num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(dist1, dist2):\n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "    for element in set(dist1.keys()).union(dist2.keys()):\n",
    "        if (dist2[element] == 0) and (dist1[element] == 0):\n",
    "            continue\n",
    "        num -= dist1[element] * np.log(dist2[element] / dist1[element])\n",
    "        \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_genre(x):\n",
    "    return {genre:len(x[genre]) for genre in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_distribution(d, type_ = \"train\"):\n",
    "    \"\"\"\n",
    "    if train: return word distribution\n",
    "    if test: return each testing example's word distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import Counter\n",
    "    from itertools import chain\n",
    "    \n",
    "    if type_ == \"train\":\n",
    "        ans = Counter(list(chain.from_iterable(d)))\n",
    "        norm = sum(ans.values())\n",
    "        for element in ans:\n",
    "            ans[element] /= norm\n",
    "            \n",
    "        impute = defaultdict(float)\n",
    "        for i in ans:\n",
    "            impute[i] = ans[i]\n",
    "\n",
    "    elif type_ == \"test\":\n",
    "        \n",
    "        ans = []\n",
    "        for song in d:\n",
    "            ans1 = Counter(list(chain.from_iterable(song)))\n",
    "            norm = sum(ans1.values())\n",
    "            for element in ans1:\n",
    "                ans1[element] /= norm \n",
    "            impute = defaultdict(float)\n",
    "            for i in ans1:\n",
    "                impute[i] = ans1[i]\n",
    "            ans.append(ans1)\n",
    "            \n",
    "            \n",
    "    return impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdist = get_word_distribution(pop)\n",
    "rapdist = get_word_distribution(rap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = {\"pop\": popdist, \"rap\": rapdist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptest = make_lyrics(vocab, 100, 400, 100, \"pop\", popprob)\n",
    "raptest = make_lyrics(vocab, 100, 400, 100, \"rap\", rapprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptest2 = get_word_distribution(poptest, \"test\")\n",
    "raptest2 = get_word_distribution(raptest, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, dists, popprop, rapprop):\n",
    "    p_genre = {\"pop\": popprop, \"rap\": rapprop}\n",
    "    results = []\n",
    "    for song in data:\n",
    "        distance = {}\n",
    "        for dist in dists:\n",
    "            distance.update({dist: hellinger_distance(song, dists[dist]) * p_genre[dist]})\n",
    "        #print(distance)\n",
    "        results.append(max(distance.items(), key = lambda x: x[1]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classify(raptest2, dists, .5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classify(poptest2, dists, .5, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv(\"..//..//data//Weekly_data_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = []\n",
    "for word in range(len(df)):\n",
    "    if re.search(\"pop\", df.loc[word, \"Genre\"], flags = re.I) != None:\n",
    "        pop.append(True)\n",
    "    else:\n",
    "        pop.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = df.ID.unique()\n",
    "np.random.shuffle(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df.ID.isin(IDs[:int(.8 * len(IDs))])]\n",
    "test = df[df.ID.isin(IDs[int(.8 * len(IDs)):])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptrain = train[train[\"Pop\"] == True].word\n",
    "raptrain = train[train[\"Pop\"] == False].word\n",
    "\n",
    "poptest = test[test[\"Pop\"] == True]\n",
    "raptest = test[test[\"Pop\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_distribution(d, type_ = \"train\"):\n",
    "    \"\"\"\n",
    "    if train: return word distribution\n",
    "    if test: return each testing example's word distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import Counter\n",
    "    from itertools import chain\n",
    "    \n",
    "    if type_ == \"train\":\n",
    "        ans = Counter(list(d))\n",
    "        norm = sum(ans.values())\n",
    "        for element in ans:\n",
    "            ans[element] /= norm\n",
    "            \n",
    "        impute = defaultdict(float)\n",
    "        for i in ans:\n",
    "            impute[i] = ans[i]\n",
    "        return impute\n",
    "\n",
    "    elif type_ == \"test\":\n",
    "        \n",
    "        ans = []\n",
    "        for song in d.ID.unique():\n",
    "            ans1 = Counter(list(d[d.ID == song].word))\n",
    "            norm = sum(ans1.values())\n",
    "            for element in ans1:\n",
    "                ans1[element] /= norm\n",
    "                \n",
    "            impute = defaultdict(float)\n",
    "            for i in ans1:\n",
    "                impute[i] = ans1[i]\n",
    "            ans.append(ans1)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, dists, popprop, rapprop):\n",
    "    p_genre = {\"pop\": popprop, \"rap\": rapprop}\n",
    "    results = []\n",
    "    for song in data:\n",
    "        distance = {}\n",
    "        for dist in dists:\n",
    "            distance.update({dist: hellinger_distance(song, dists[dist])})# * p_genre[dist]})\n",
    "        #print(distance)\n",
    "        results.append(max(distance.items(), key = lambda x: x[1]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptraindist = get_word_distribution(poptrain)\n",
    "raptraindist = get_word_distribution(raptrain)\n",
    "dists = {\"pop\": poptraindist, \"rap\": raptraindist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptestdist = get_word_distribution(poptest, \"test\")\n",
    "raptestdist = get_word_distribution(raptest, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpop = len(train[train.Pop == True].ID.unique())\n",
    "numrap = len(train[train.Pop == False].ID.unique())\n",
    "popprop = numpop / (numpop + numrap)\n",
    "rapprop = 1 - popprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops = [x[0] for x in classify(poptestdist, dists, popprop, rapprop)]\n",
    "raps = [x[0] for x in classify(raptestdist, dists, popprop, rapprop)]\n",
    "predicted = pops + raps\n",
    "true = [\"pop\" for _ in range(len(pops))] + [\"rap\" for _ in range(len(raps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(predicted, true).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 164, 45, 250)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46786632390745503"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pops) / (len(pops) + len(raps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313624678663239"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tn + tp) / (tn + fp + fn + tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher than naive classifier!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6038647342995169"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847457627118644"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp + fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
