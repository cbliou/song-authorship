{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import html2text as ht\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import traceback\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Billboard for song titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DateTracker:\n",
    "    \n",
    "    days = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, \n",
    "            7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "    \n",
    "    def __init__(self, year = None, month = None, day = None):\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.day = day\n",
    "        \n",
    "    def previous_week(self):\n",
    "        \n",
    "        if (self.year == 1958) and (self.month == 8) and (0 < self.day <= 7):\n",
    "            return\n",
    "        \n",
    "        # if move to previous month\n",
    "        if self.day - 7 <= 0:\n",
    "            \n",
    "            if self.month != 1:\n",
    "                \n",
    "                self.month -= 1\n",
    "                self.day += self.days[self.month] - 7\n",
    "            \n",
    "            # if move to previous year\n",
    "            else:\n",
    "                \n",
    "                self.year -= 1\n",
    "                self.month = 12\n",
    "                self.day += self.days[self.month] - 7\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            self.day -= 7\n",
    "            \n",
    "    def as_date(self):\n",
    "        \n",
    "        return \"%04d-%02d-%02d\" % (self.year, self.month, self.day)\n",
    "        \n",
    "        \n",
    "class Song:\n",
    "    \n",
    "    def __init__(self, artist, name, rank, peakpos, weeksonchart, date):\n",
    "        self.artist = artist\n",
    "        self.name = name\n",
    "        self.rank = rank\n",
    "        self.peakpos = peakpos\n",
    "        self.weeksonchart = weeksonchart\n",
    "        self.date = date\n",
    "        \n",
    "    def get_artist(self):\n",
    "        return self.artist\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_rank(self):\n",
    "        return self.rank\n",
    "    \n",
    "    def get_peak_pos(self):\n",
    "        return self.peakpos\n",
    "    \n",
    "    def get_weeks_on_chart(self):\n",
    "        return self.weeksonchart\n",
    "    \n",
    "    def get_date(self):\n",
    "        return self.date\n",
    "    \n",
    "    def list_form(self):\n",
    "        return [self.artist, self.name, self.rank, self.peakpos,\n",
    "                self.weeksonchart, self.date]\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"\\n\".join([str(x) for x in [self.artist, self.name,\n",
    "                                          self.rank, self.peakpos,\n",
    "                                          self.weeksonchart, self.date]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    bad = {\"\\\\\\\\n\": \"\\n\", \n",
    "           \"\\n+\": \"\\n\", \n",
    "           \"\\n\": \" - \",\n",
    "           \"\\[\\]\\(.{0,}?\\)\": \"\",\n",
    "           \"\\[Play\\]\\(.{0,}?\\)\": \"\",\n",
    "           \"\\[\\s{0,5}-\\s{0,5}Song\\s{0,5}-\\s{0,5}Lyrics\\s{0,5}-\\s{0,5}\\]\\(.{0,}?\\)\": \"\"}\n",
    "\n",
    "    for x in bad:\n",
    "        text = re.sub(x, bad[x], text, flags = re.I | re.S)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def clean_line(text):\n",
    "    repl = {\"weeks at no. 1\": \"\",\n",
    "            \"(-\\s{1,4}!)+\": \"\",\n",
    "            \"(?<![A-z])! -\": \"\",\n",
    "            \"_\": \"\",\n",
    "            \"\\[\\s-\": \"\", \n",
    "            \"-\\s\\]\": \"\",\n",
    "            \"\\[.{0,}?\\]|\\(.{0,}?\\)\": \"\",\n",
    "            \"\\s+\": \" \",\n",
    "            \"(-\\s{1,5})+\": \"- \",}    \n",
    "    \n",
    "    for x in repl:\n",
    "        text = re.sub(x, repl[x], text, flags = re.I | re.S)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_songs_by_week(weeks = 100):\n",
    "    \n",
    "    filler = [\" and \", \" featuring \", \" & \", \" x \", \" / \"]\n",
    "    namesub = {\"f\\*\\*k\": \"fuck\", \"s\\*\\*t\": \"shit\"}\n",
    "    path = \"https://www.billboard.com/charts/hot-100\"\n",
    "    curdate = DateTracker(year = 2018, month = 8, day = 11)\n",
    "    songs = []\n",
    "\n",
    "    for j in range(weeks):\n",
    "        \n",
    "        page = requests.get(path + \"/\" + curdate.as_date())\n",
    "        if j % 20 == 0:\n",
    "            print(\"We are on week {}, it is {}\".format(j, curdate.as_date()))\n",
    "\n",
    "        data = ht.html2text(str(page.content))\n",
    "        data = clean_text(data)\n",
    "        data = re.split(\"date search |in performance - |on chart - \", data, flags = re.I)[1:]\n",
    "\n",
    "        #first one\n",
    "        weeksoc = int(re.search(\"[0-9]{0,1}\\s-\\sweeks\", \n",
    "                                re.sub(\"weeks at no. 1\", \"\", data[0], flags = re.I | re.S),\n",
    "                                flags = re.I | re.S).group()[:2])\n",
    "        tmp = clean_line(data[1]).strip().split(\"-\")\n",
    "        name = tmp[0].strip()\n",
    "        for k in namesub:\n",
    "            name = re.sub(k, namesub[k], name, flags = re.I | re.S)\n",
    "        artist = tmp[1].strip()\n",
    "        for k in filler:\n",
    "            artist = re.sub(k, \", \", artist, flags = re.I | re.S)\n",
    "\n",
    "        songs.append(Song(artist = artist, name = name, rank = 1,\n",
    "                          peakpos = 1, weeksonchart = weeksoc, \n",
    "                          date = curdate.as_date()))\n",
    "\n",
    "\n",
    "        #everything else (2 - 100)\n",
    "        for i in data[2:]:\n",
    "            #we know we have a rank\n",
    "            if re.match(\"^[0-9]{0,3}\", i.strip()).group() != \"\":\n",
    "                i = clean_line(i)\n",
    "                tmp = i.split(\"-\")\n",
    "                rank = tmp[0].strip()\n",
    "                name = tmp[1].strip()\n",
    "                for k in namesub:\n",
    "                    name = re.sub(k, namesub[k], name, flags = re.I | re.S)\n",
    "                artist = tmp[2].strip()\n",
    "                for k in filler:\n",
    "                    artist = re.sub(k, \", \", artist, flags = re.I | re.S)\n",
    "                    \n",
    "                #if these are empty they're debuts!\n",
    "                try:\n",
    "                    peakpos = int(re.search(\"[0-9]{0,3}\\s-\\speak position\", i, flags = re.I | re.S).group().split(\" \")[0])\n",
    "                except AttributeError:\n",
    "                    peakpos = \"\"\n",
    "                try:\n",
    "                    weeksoc = int(re.search(\"[0-9]{0,3}\\s-\\sweeks\", i, flags = re.I | re.S).group().split(\" \")[0])\n",
    "                except AttributeError:\n",
    "                    weeksoc = \"\"\n",
    "\n",
    "                songs.append(Song(artist = artist, name = name, rank = rank,\n",
    "                                  peakpos = peakpos, weeksonchart = weeksoc,\n",
    "                                  date = curdate.as_date()))\n",
    "\n",
    "        curdate.previous_week()\n",
    "        \n",
    "    return songs, curdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on week 0, it is 2018-08-11\n"
     ]
    }
   ],
   "source": [
    "songs, curdate = get_songs_by_week(weeks = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep = np.array([x.list_form() for x in songs])\n",
    "df = pd.DataFrame({\n",
    "    \"Artists\": prep[:, 0],\n",
    "    \"Name\": prep[:, 1],\n",
    "    \"Weekly rank\": prep[:, 2],\n",
    "    \"Peak position\": prep[:, 3],\n",
    "    \"Weeks on chart\": prep[:, 4],\n",
    "    \"Week\": prep[:, 5]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Weekly_ranks.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Genius for lyrics, genre, etc.\n",
    "\n",
    "\n",
    "Song name\n",
    "\n",
    "Artist/Group\n",
    "\n",
    "Weekly rank \n",
    "\n",
    "Peak rank\n",
    "\n",
    "Year published\n",
    "\n",
    "Genre\n",
    "\n",
    "Writing Credits\n",
    "\n",
    "Lyrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyric_link(artists, name, both = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the link of the song name given artists + name of the song\n",
    "    \"\"\"\n",
    "    \n",
    "    client_token = \"BrGsH3KoiMzSyCUClF4-TyzjrNfQfrr2-Q9bfK6Bhum1fquRgVf0rn-Pq6mr9Uyc\"\n",
    "    headers = {\"Authorization\": \"Bearer \" + client_token}\n",
    "    link = \"https://api.genius.com/search?q=\"\n",
    "    space = \"%20\"\n",
    "    \n",
    "    #this could prove disastrous, double check it...\n",
    "    # update: yes it did, just replace accents.\n",
    "    name_repl = {\"Beyonce\": \"Beyoncé\", \n",
    "                 \"Amine\": \"Aminé\",\n",
    "                 \"D.R.A.M.\": \"DRAM\",\n",
    "                 \"$ign\": \"\\$ign\"}\n",
    "    \n",
    "    repl = {\n",
    "        \"a|á|ạ|à|ả|ã|ă|ắ|ặ|ằ|ẳ|ẵ|â|ấ|ậ|ầ|ẩ|ẫ\": \"a\",\n",
    "        \"é|ẹ|è|ẻ|ẽ|ê|ế|ệ|ề|ể|ễ\": \"e\",\n",
    "        \"í|ị|ì|ỉ|ĩ\": \"i\",\n",
    "        \"ó|ọ|ò|ỏ|õ|ô|ố|ộ|ồ|ổ|ỗ|ơ|ớ|ợ|ờ|ỡ\": \"o\",\n",
    "        \"ú|ụ|ù|ủ|ũ|ư|ứ|ự|ừ|ử|ữ\": \"u\",\n",
    "        \"ý|ỵ|ỳ|ỷ|ỹ\": \"y\"\n",
    "    }\n",
    "\n",
    "    artists = re.sub(\",\", \"\", artists)\n",
    "    name = re.sub(\",\", \"\", name)\n",
    "    if both:\n",
    "        page = requests.get(link + re.sub(\" \", space, name) +\n",
    "                            space + re.sub(\" \", space, artists), headers = headers)\n",
    "    else:\n",
    "        page = requests.get(link + re.sub(\" \", space, name), headers = headers)\n",
    "        \n",
    "    # data\n",
    "    page = json.loads(page.content)[\"response\"][\"hits\"] \n",
    "    check = [re.sub(\",\", \"\", x) for x in artists.split(\" \") + name.split(\" \") if x not in string.punctuation]\n",
    "    \n",
    "    # remove accents from \n",
    "    for i in repl:\n",
    "        for j in range(len(check)):\n",
    "            check[j] = re.sub(i, repl[i], check[j], flags = re.I | re.S)\n",
    "    \n",
    "    top = []\n",
    "\n",
    "    \n",
    "    \n",
    "    if len(page) == 1:\n",
    "        return page[0][\"result\"][\"path\"]\n",
    "    else:\n",
    "        for i in range(len(page)):\n",
    "            c = 0\n",
    "            \n",
    "            # remove accents from title\n",
    "            title = page[i][\"result\"][\"full_title\"]\n",
    "            for j in repl:\n",
    "                title = re.sub(j, repl[j], title, flags = re.I | re.S)\n",
    "\n",
    "            # check if every artist + name token in the full title\n",
    "            for j in check:\n",
    "                if re.search(j, title, flags = re.I | re.S) != None:\n",
    "                    c += 1\n",
    "            if c == len(check):\n",
    "                return page[i][\"result\"][\"path\"]\n",
    "\n",
    "        \n",
    "    #if we are here, search failed. now we include the artists as well\n",
    "    if both == False:\n",
    "        return get_lyric_link(artists, name, True)\n",
    "    \n",
    "    top = []\n",
    "    \n",
    "    #if here, find most popular song\n",
    "    print(\"ripperino, hopefully we never see this message.\")\n",
    "    for j in range(len(page)):\n",
    "        try:\n",
    "            top.append(page[i][\"result\"][\"stats\"][\"pageviews\"])\n",
    "        except Exception:\n",
    "            top.append(-1)\n",
    "    return page[np.argmax(top)][\"result\"][\"path\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape_lyrics(row, snip):\n",
    "    \n",
    "    #print(snip)\n",
    "    base_link = \"https://genius.com\"\n",
    "    content = requests.get(base_link + snip).content\n",
    "    data = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    # get all writers (expensive search)\n",
    "    \n",
    "    meta_data = content.decode(\"utf8\")\n",
    "    \n",
    "    start_meta_regex = \"verified_lyrics_by.*?writer_artists&quot\"\n",
    "    stop_meta_regex = \"itemprop=\\\"page_data\\\"\"\n",
    "    write_regex = \"https://genius.com/artists/[^&]*\"\n",
    "\n",
    "    start = re.search(start_meta_regex, meta_data, flags = re.I | re.S).end()\n",
    "    stop = re.search(stop_meta_regex, meta_data, flags = re.I | re.S).end()\n",
    "    meta_data = meta_data[start:stop]\n",
    "\n",
    "    write_links = re.findall(write_regex, meta_data)\n",
    "    write = [re.sub(\"https://genius.com/artists/\", \"\", x) for x in write_links]\n",
    "    write = \", \".join([re.sub(\"-\", \" \", x) for x in write])\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    #subset data to search for lyrics\n",
    "    \n",
    "    genre_sub = {\"\\\"\": \" \", \"genius\": \"\", \"\\s+,\": \",\"}\n",
    "    lyric_regex = row[\"Name\"] + \".{0,20}?Lyrics.+?More on Genius\"\n",
    "    genre_regex = \"genres\\\":\\[.+?\\]\"\n",
    "    track_info_regex = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?remixed by\"\n",
    "    track_info_regex2 = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?cover by\"\n",
    "    date_regex = \"release date.{0,15}?20[0-9][0-9]\"\n",
    "    write_regex = \"Written By\\n+.+?\\n\"\n",
    "    \n",
    "    data = data[re.search(base_link + snip, data).end():]\n",
    "    \n",
    "    lyrics = re.search(lyric_regex, data, flags = re.I | re.S).group()[:-15]\n",
    "    \n",
    "    try:\n",
    "        genre = re.search(\"\\[.+?\\]\", re.search(genre_regex, data, flags = re.I | re.S).group()).group()[1:-1]\n",
    "        for k in genre_sub:\n",
    "            genre = re.sub(k, genre_sub[k], genre, flags = re.I)\n",
    "    except AttributeError:\n",
    "        genre = \"\"\n",
    "    \n",
    "        \n",
    "    try:\n",
    "        date = re.split(\"\\n+\", re.search(date_regex, data, flags = re.I | re.S).group())[-1]\n",
    "    except AttributeError:\n",
    "        date = \"\"\n",
    "        \n",
    "    return date, genre, write, lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "genre = []\n",
    "write = []\n",
    "lyrics = []\n",
    "checker = {}\n",
    "\n",
    "for i in range(32, len(df)):\n",
    "    \n",
    "    art = df.iloc[i][\"Artists\"]\n",
    "    name = df.iloc[i][\"Name\"]\n",
    "    \n",
    "    # haven't scraped the song lyrics yet\n",
    "    \n",
    "    if art + name not in checker:\n",
    "        try:\n",
    "            \n",
    "            temp = get_lyric_link(art, name)\n",
    "            checker.update({art + name: i})\n",
    "            d, g, w, l = scrape_lyrics(df.iloc[i], temp)\n",
    "            \n",
    "        except Exception:\n",
    "            \n",
    "            print(i)\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "            \n",
    "        dates.append(d)\n",
    "        genre.append(g)\n",
    "        write.append(w)\n",
    "        lyrics.append(l)\n",
    "    \n",
    "    # already scraped song lyrics\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        num = checker[art + name]\n",
    "        d, g, w, l = dates[num], genre[num], write[num], lyrics[num]\n",
    "        \n",
    "        dates.append(d)\n",
    "        genre.append(g)\n",
    "        write.append(w)\n",
    "        lyrics.append(l)        \n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(\"We are {}% done\".format(round(i / len(df) * 100, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Te Boté (Remix) by Nio García, Casper Mágico & Bad Bunny (Ft. Darell, Nicky Jam & Ozuna)\n",
      "Te Bote (Remix) by Nio Garcia, Casper Magico & Bad Bunny (Ft. Darell, Nicky Jam & Ozuna) ['Casper', 'Magico', 'Nio', 'Garcia', 'Darell', 'Nicky', 'Jam', 'Ozuna', 'Bad', 'Bunny', 'Te', 'Bote']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Nio-garcia-casper-magico-and-bad-bunny-te-bote-remix-lyrics'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lyric_link(df.iloc[39][\"Artists\"], df.iloc[39][\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Casper Magico, Nio Garcia, Darell, Nicky Jam, Ozuna, Bad Bunny'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[39].Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artists           Casper Magico, Nio Garcia, Darell, Nicky Jam, ...\n",
       "Name                                                        Te Bote\n",
       "Peak position                                                    36\n",
       "Week                                                     2018-08-11\n",
       "Weekly rank                                                      41\n",
       "Weeks on chart                                                   15\n",
       "Name: 39, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[39]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
