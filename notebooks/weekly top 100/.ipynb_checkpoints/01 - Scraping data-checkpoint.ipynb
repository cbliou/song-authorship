{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import html2text as ht\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import traceback\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Billboard for song titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DateTracker:\n",
    "    \n",
    "    days = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, \n",
    "            7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "    \n",
    "    def __init__(self, year = None, month = None, day = None):\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.day = day\n",
    "        \n",
    "    def previous_week(self):\n",
    "        \n",
    "        if (self.year == 1958) and (self.month == 8) and (0 < self.day <= 7):\n",
    "            return\n",
    "        \n",
    "        # if move to previous month\n",
    "        if self.day - 7 <= 0:\n",
    "            \n",
    "            if self.month != 1:\n",
    "                \n",
    "                self.month -= 1\n",
    "                self.day += self.days[self.month] - 7\n",
    "            \n",
    "            # if move to previous year\n",
    "            else:\n",
    "                \n",
    "                self.year -= 1\n",
    "                self.month = 12\n",
    "                self.day += self.days[self.month] - 7\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            self.day -= 7\n",
    "            \n",
    "    def as_date(self):\n",
    "        \n",
    "        return \"%04d-%02d-%02d\" % (self.year, self.month, self.day)\n",
    "        \n",
    "        \n",
    "class Song:\n",
    "    \n",
    "    def __init__(self, artist, name, rank, peakpos, weeksonchart, date):\n",
    "        self.artist = artist\n",
    "        self.name = name\n",
    "        self.rank = rank\n",
    "        self.peakpos = peakpos\n",
    "        self.weeksonchart = weeksonchart\n",
    "        self.date = date\n",
    "        \n",
    "    def get_artist(self):\n",
    "        return self.artist\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_rank(self):\n",
    "        return self.rank\n",
    "    \n",
    "    def get_peak_pos(self):\n",
    "        return self.peakpos\n",
    "    \n",
    "    def get_weeks_on_chart(self):\n",
    "        return self.weeksonchart\n",
    "    \n",
    "    def get_date(self):\n",
    "        return self.date\n",
    "    \n",
    "    def list_form(self):\n",
    "        return [self.artist, self.name, self.rank, self.peakpos,\n",
    "                self.weeksonchart, self.date]\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"\\n\".join([str(x) for x in [self.artist, self.name,\n",
    "                                          self.rank, self.peakpos,\n",
    "                                          self.weeksonchart, self.date]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    bad = {\"\\\\\\\\n\": \"\\n\", \n",
    "           \"\\n+\": \"\\n\", \n",
    "           \"\\n\": \" - \",\n",
    "           \"\\[\\]\\(.{0,}?\\)\": \"\",\n",
    "           \"\\[Play\\]\\(.{0,}?\\)\": \"\",\n",
    "           \"\\[\\s{0,5}-\\s{0,5}Song\\s{0,5}-\\s{0,5}Lyrics\\s{0,5}-\\s{0,5}\\]\\(.{0,}?\\)\": \"\"}\n",
    "\n",
    "    for x in bad:\n",
    "        text = re.sub(x, bad[x], text, flags = re.I | re.S)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def clean_line(text):\n",
    "    repl = {\"weeks at no. 1\": \"\",\n",
    "            \"(-\\s{1,4}!)+\": \"\",\n",
    "            \"(?<![A-z])! -\": \"\",\n",
    "            \"_\": \"\",\n",
    "            \"\\[\\s-\": \"\", \n",
    "            \"-\\s\\]\": \"\",\n",
    "            \"\\[.{0,}?\\]|\\(.{0,}?\\)\": \"\",\n",
    "            \"\\s+\": \" \",\n",
    "            \"(-\\s{1,5})+\": \"- \",}    \n",
    "    \n",
    "    for x in repl:\n",
    "        text = re.sub(x, repl[x], text, flags = re.I | re.S)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_songs_by_week(weeks = 100):\n",
    "    \n",
    "    #filler = [\" and \", \" featuring \", \" & \", \" x \", \" / \"]\n",
    "    namesub = {\"f\\*\\*k\": \"fuck\", \"s\\*\\*t\": \"shit\"}\n",
    "    path = \"https://www.billboard.com/charts/hot-100\"\n",
    "    curdate = DateTracker(year = 2018, month = 8, day = 11)\n",
    "    songs = []\n",
    "\n",
    "    for j in range(weeks):\n",
    "        \n",
    "        page = requests.get(path + \"/\" + curdate.as_date())\n",
    "        if j % 20 == 0:\n",
    "            print(\"We are on week {}, it is {}\".format(j, curdate.as_date()))\n",
    "\n",
    "        data = ht.html2text(str(page.content))\n",
    "        data = clean_text(data)\n",
    "        data = re.split(\"date search |in performance - |on chart - \", data, flags = re.I)[1:]\n",
    "\n",
    "        #first one\n",
    "        weeksoc = int(re.search(\"[0-9]{0,1}\\s-\\sweeks\", \n",
    "                                re.sub(\"weeks at no. 1\", \"\", data[0], flags = re.I | re.S),\n",
    "                                flags = re.I | re.S).group()[:2])\n",
    "        tmp = clean_line(data[1]).strip().split(\"-\")\n",
    "        name = tmp[0].strip()\n",
    "        for k in namesub:\n",
    "            name = re.sub(k, namesub[k], name, flags = re.I | re.S)\n",
    "        artist = tmp[1].strip()\n",
    "        # for k in filler:\n",
    "        #     artist = re.sub(k, \", \", artist, flags = re.I | re.S)\n",
    "\n",
    "        songs.append(Song(artist = artist, name = name, rank = 1,\n",
    "                          peakpos = 1, weeksonchart = weeksoc, \n",
    "                          date = curdate.as_date()))\n",
    "\n",
    "\n",
    "        #everything else (2 - 100)\n",
    "        for i in data[2:]:\n",
    "            #we know we have a rank\n",
    "            if re.match(\"^[0-9]{0,3}\", i.strip()).group() != \"\":\n",
    "                i = clean_line(i)\n",
    "                tmp = i.split(\"-\")\n",
    "                rank = tmp[0].strip()\n",
    "                name = tmp[1].strip()\n",
    "                for k in namesub:\n",
    "                    name = re.sub(k, namesub[k], name, flags = re.I | re.S)\n",
    "                artist = tmp[2].strip()\n",
    "                # for k in filler:\n",
    "                #     artist = re.sub(k, \", \", artist, flags = re.I | re.S)\n",
    "                    \n",
    "                #if these are empty they're debuts!\n",
    "                try:\n",
    "                    peakpos = int(re.search(\"[0-9]{0,3}\\s-\\speak position\", i, flags = re.I | re.S).group().split(\" \")[0])\n",
    "                except AttributeError:\n",
    "                    peakpos = \"\"\n",
    "                try:\n",
    "                    weeksoc = int(re.search(\"[0-9]{0,3}\\s-\\sweeks\", i, flags = re.I | re.S).group().split(\" \")[0])\n",
    "                except AttributeError:\n",
    "                    weeksoc = \"\"\n",
    "\n",
    "                songs.append(Song(artist = artist, name = name, rank = rank,\n",
    "                                  peakpos = peakpos, weeksonchart = weeksoc,\n",
    "                                  date = curdate.as_date()))\n",
    "\n",
    "        curdate.previous_week()\n",
    "        \n",
    "    return songs, curdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on week 0, it is 2018-08-11\n",
      "We are on week 20, it is 2018-03-24\n",
      "We are on week 40, it is 2017-11-04\n",
      "We are on week 60, it is 2017-06-17\n",
      "We are on week 80, it is 2017-01-28\n",
      "We are on week 100, it is 2016-09-10\n",
      "We are on week 120, it is 2016-04-23\n",
      "We are on week 140, it is 2015-12-04\n",
      "We are on week 160, it is 2015-07-17\n",
      "We are on week 180, it is 2015-02-27\n"
     ]
    }
   ],
   "source": [
    "songs, curdate = get_songs_by_week(weeks = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep = np.array([x.list_form() for x in songs])\n",
    "df = pd.DataFrame({\n",
    "    \"Artists\": prep[:, 0],\n",
    "    \"Name\": prep[:, 1],\n",
    "    \"Weekly rank\": prep[:, 2],\n",
    "    \"Peak position\": prep[:, 3],\n",
    "    \"Weeks on chart\": prep[:, 4],\n",
    "    \"Week\": prep[:, 5]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Weekly_ranks.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Genius for lyrics, genre, etc.\n",
    "\n",
    "\n",
    "Song name\n",
    "\n",
    "Artist/Group\n",
    "\n",
    "Weekly rank \n",
    "\n",
    "Peak rank\n",
    "\n",
    "Year published\n",
    "\n",
    "Genre\n",
    "\n",
    "Writing Credits\n",
    "\n",
    "Lyrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artists           YG Featuring A$AP Rocky\n",
       "Name                              Handgun\n",
       "Peak position                            \n",
       "Week                           2018-08-11\n",
       "Weekly rank                            99\n",
       "Weeks on chart                           \n",
       "Name: 97, dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.search(\"A\\$aP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(19, 23), match='a$aP'>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"A\\$AP\", \"HaNDGUN by YG (Ft. a$aP Rocky)\", flags = re.I | re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YG', 'A\\\\$AP', 'Rocky', 'Handgun']\n",
      "HaNDGUN by YG (Ft. a$aP Rocky)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Yg-handgun-lyrics'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lyric_link(df.iloc[97][\"Artists\"], df.iloc[97][\"Name\"], debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyric_link(artists, name, both = False, debug = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the link of the song name given artists + name of the song\n",
    "    \"\"\"\n",
    "    \n",
    "    client_token = \"BrGsH3KoiMzSyCUClF4-TyzjrNfQfrr2-Q9bfK6Bhum1fquRgVf0rn-Pq6mr9Uyc\"\n",
    "    headers = {\"Authorization\": \"Bearer \" + client_token}\n",
    "    link = \"https://api.genius.com/search?q=\"\n",
    "    space = \"%20\"\n",
    "    \n",
    "    #this could prove disastrous, double check it...\n",
    "    # update: yes it did, just replace accents.\n",
    "    name_repl = {\"Beyonce\": \"Beyoncé\", \n",
    "                 \"Amine\": \"Aminé\",\n",
    "                 \"D.R.A.M.\": \"DRAM\",\n",
    "                 \"$ign\": \"\\$ign\"}\n",
    "    repl = {\n",
    "        \"a|á|ạ|à|ả|ã|ă|ắ|ặ|ằ|ẳ|ẵ|â|ấ|ậ|ầ|ẩ|ẫ\": \"a\",\n",
    "        \"é|ẹ|è|ẻ|ẽ|ê|ế|ệ|ề|ể|ễ|ë\": \"e\",\n",
    "        \"í|ị|ì|ỉ|ĩ\": \"i\",\n",
    "        \"ó|ọ|ò|ỏ|õ|ô|ố|ộ|ồ|ổ|ỗ|ơ|ớ|ợ|ờ|ỡ\": \"o\",\n",
    "        \"ú|ụ|ù|ủ|ũ|ư|ứ|ự|ừ|ử|ữ\": \"u\",\n",
    "        \"ý|ỵ|ỳ|ỷ|ỹ\": \"y\"\n",
    "    }\n",
    "    artistregex = {\n",
    "        \"\\$\": \"\\\\\\\\$\"\n",
    "    }\n",
    "    filler = [\" and \", \" featuring \", \" & \", \" x \", \" / \"]\n",
    "\n",
    "    artists = re.sub(\",\", \"\", artists)\n",
    "    name = re.sub(\",\", \"\", name)\n",
    "    if both:\n",
    "        page = requests.get(link + re.sub(\" \", space, name) +\n",
    "                            space + re.sub(\" \", space, artists), headers = headers)\n",
    "    else:\n",
    "        page = requests.get(link + re.sub(\" \", space, name), headers = headers)\n",
    "        \n",
    "    # now that we searched, remove filler words that may not appear\n",
    "    # in actual song title\n",
    "    page = json.loads(page.content)[\"response\"][\"hits\"]\n",
    "    for i in filler:\n",
    "        artists = re.sub(i, \" \", artists, flags = re.I | re.S)\n",
    "    check = [re.sub(\",\", \"\", x) for x in artists.split(\" \") + name.split(\" \") if x not in string.punctuation]\n",
    "\n",
    "\n",
    "    # fix artist tokens to be used in re.search\n",
    "    for i in artistregex:\n",
    "        for j in range(len(check)):\n",
    "            check[j] = re.sub(i, artistregex[i], check[j], flags = re.I | re.S)\n",
    "            \n",
    "    if debug:\n",
    "        print(check)    \n",
    "        \n",
    "    top = []\n",
    "\n",
    "    \n",
    "    \n",
    "    if len(page) == 1:\n",
    "        return page[0][\"result\"][\"path\"]\n",
    "    else:\n",
    "        for i in range(len(page)):\n",
    "            c = 0\n",
    "            \n",
    "            # remove accents from title\n",
    "            title = page[i][\"result\"][\"full_title\"]\n",
    "            for j in repl:\n",
    "                title = re.sub(j, repl[j], title, flags = re.I | re.S)\n",
    "\n",
    "            if debug:\n",
    "                print(title)\n",
    "                \n",
    "            # check if every artist + name token in the full title\n",
    "            for j in check:\n",
    "                if re.search(j, title, flags = re.I | re.S) != None:\n",
    "                    c += 1\n",
    "            if c == len(check):\n",
    "                try:\n",
    "                    if page[i][\"result\"][\"stats\"][\"pageviews\"] > 0:\n",
    "                        return page[i][\"result\"][\"path\"]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "        \n",
    "    #if we are here, search failed. now we include the artists as well\n",
    "    if both == False:\n",
    "        return get_lyric_link(artists, name, True)\n",
    "    \n",
    "    top = []\n",
    "    \n",
    "    #if here, find most popular song\n",
    "    print()\n",
    "    print(\"hopefully we never see this message.\")\n",
    "    print(artists, name)\n",
    "    for j in range(len(page)):\n",
    "        try:\n",
    "            top.append(page[i][\"result\"][\"stats\"][\"pageviews\"])\n",
    "        except Exception:\n",
    "            top.append(-1)\n",
    "    print(page[np.argmax(top)][\"result\"][\"path\"])\n",
    "    print()\n",
    "    return page[np.argmax(top)][\"result\"][\"path\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape_lyrics(row, snip):\n",
    "    \n",
    "    # fix artist names w/ these\n",
    "    repl = {\n",
    "        \"á|ạ|à|ả|ã|ă|ắ|ặ|ằ|ẳ|ẵ|â|ấ|ậ|ầ|ẩ|ẫ\": \"a\",\n",
    "        \"é|ẹ|è|ẻ|ẽ|ê|ế|ệ|ề|ể|ễ|ë\": \"e\",\n",
    "        \"í|ị|ì|ỉ|ĩ\": \"i\",\n",
    "        \"ó|ọ|ò|ỏ|õ|ô|ố|ộ|ồ|ổ|ỗ|ơ|ớ|ợ|ờ|ỡ\": \"o\",\n",
    "        \"ú|ụ|ù|ủ|ũ|ư|ứ|ự|ừ|ử|ữ\": \"u\",\n",
    "        \"ý|ỵ|ỳ|ỷ|ỹ\": \"y\",\n",
    "        \"\\$\": \"\\\\\\\\$\"\n",
    "    }\n",
    "    \n",
    "    #print(snip)\n",
    "    base_link = \"https://genius.com\"\n",
    "    content = requests.get(base_link + snip).content\n",
    "    data = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    # get all writers (expensive search)\n",
    "    \n",
    "    meta_data = content.decode(\"utf8\")\n",
    "    \n",
    "    start_meta_regex = \"verified_lyrics_by.*?writer_artists&quot\"\n",
    "    stop_meta_regex = \"itemprop=\\\"page_data\\\"\"\n",
    "    write_regex = \"https://genius.com/artists/[^&]*\"\n",
    "\n",
    "    start = re.search(start_meta_regex, meta_data, flags = re.I | re.S).end()\n",
    "    stop = re.search(stop_meta_regex, meta_data, flags = re.I | re.S).end()\n",
    "    meta_data = meta_data[start:stop]\n",
    "\n",
    "    write_links = re.findall(write_regex, meta_data)\n",
    "    write = [re.sub(\"https://genius.com/artists/\", \"\", x) for x in write_links]\n",
    "    write = \", \".join([re.sub(\"-\", \" \", x) for x in write])\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    #subset data to search for lyrics\n",
    "    \n",
    "    genre_sub = {\"\\\"\": \" \", \"genius\": \"\", \"\\s+,\": \",\"}\n",
    "    lyric_regex = row[\"Name\"] + \".{0,20}?Lyrics.+?More on Genius\"\n",
    "    genre_regex = \"genres\\\":\\[.+?\\]\"\n",
    "    track_info_regex = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?remixed by\"\n",
    "    track_info_regex2 = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?cover by\"\n",
    "    date_regex = \"release date.{0,15}?20[0-9][0-9]\"\n",
    "    write_regex = \"Written By\\n+.+?\\n\"\n",
    "    \n",
    "    data = data[re.search(base_link + snip, data).end():]\n",
    "    for i in repl:\n",
    "        data = re.sub(i, repl[i], data, flags = re.I | re.S)\n",
    "    \n",
    "    lyrics = re.search(lyric_regex, data, flags = re.I | re.S).group()[:-15]\n",
    "    \n",
    "    try:\n",
    "        genre = re.search(\"\\[.+?\\]\", re.search(genre_regex, data, flags = re.I | re.S).group()).group()[1:-1]\n",
    "        for k in genre_sub:\n",
    "            genre = re.sub(k, genre_sub[k], genre, flags = re.I)\n",
    "    except AttributeError:\n",
    "        genre = \"\"\n",
    "    \n",
    "        \n",
    "    try:\n",
    "        date = re.split(\"\\n+\", re.search(date_regex, data, flags = re.I | re.S).group())[-1]\n",
    "    except AttributeError:\n",
    "        date = \"\"\n",
    "        \n",
    "    return date, genre, write, lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are 0.0% done\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "genre = []\n",
    "write = []\n",
    "lyrics = []\n",
    "checker = {}\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    art = df.iloc[i][\"Artists\"]\n",
    "    name = df.iloc[i][\"Name\"]\n",
    "    \n",
    "    # haven't scraped the song lyrics yet\n",
    "    \n",
    "    if art + name not in checker:\n",
    "        try:\n",
    "            \n",
    "            temp = get_lyric_link(art, name)\n",
    "            checker.update({art + name: i})\n",
    "            d, g, w, l = scrape_lyrics(df.iloc[i], temp)\n",
    "            \n",
    "        except Exception:\n",
    "            \n",
    "            #rough hack to just skip for now\n",
    "            #that way we can view all the errors in one go!!\n",
    "            #i need to sleep...\n",
    "            print(i)\n",
    "            traceback.print_exc()\n",
    "            dates.append(\"\")\n",
    "            genre.append(\"\")\n",
    "            write.append(\"\")\n",
    "            lyrics.append(\"\")\n",
    "            continue\n",
    "            \n",
    "        dates.append(d)\n",
    "        genre.append(g)\n",
    "        write.append(w)\n",
    "        lyrics.append(l)\n",
    "    \n",
    "    # already scraped song lyrics\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        num = checker[art + name]\n",
    "        d, g, w, l = dates[num], genre[num], write[num], lyrics[num]\n",
    "        \n",
    "        dates.append(d)\n",
    "        genre.append(g)\n",
    "        write.append(w)\n",
    "        lyrics.append(l)        \n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(\"We are {}% done\".format(round(i / len(df) * 100, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artists                  Ariana Grande\n",
       "Name              No Tears Left To Cry\n",
       "Peak position                        3\n",
       "Week                        2018-08-04\n",
       "Weekly rank                         11\n",
       "Weeks on chart                      14\n",
       "Name: 108, dtype: object"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[108]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug log:\n",
    " - Te Bote: accent error\n",
    " - Tiesto: accent error\n",
    " - Logic, Ryan Tedder: just checked hot links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_link = \"https://genius.com\"\n",
    "content = requests.get(base_link + \"/Nio-garcia-casper-magico-and-bad-bunny-te-bote-remix-lyrics\").content\n",
    "data = BeautifulSoup(content, \"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artists           YG Featuring A$AP Rocky\n",
       "Name                              Handgun\n",
       "Peak position                            \n",
       "Week                           2018-08-11\n",
       "Weekly rank                            99\n",
       "Weeks on chart                           \n",
       "Name: 97, dtype: object"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[97]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
