---
title: "EDA - First Draft"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(purrr)
library(magrittr)
library(tidyr)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
library(tm)
library(topicmodels)
library(broom)
```

First, let's define the word "Robotic" to refer to songs where an external songwriter was credited. In this notebook, we do several exploratory analyses:

- Log-odds ratio of words in robotic songs and words in non-robotic songs
- Sentiment analysis between robotic and non-robotic songs
- Latent Dirichlet Allocation, unsupervised

We first read in our data. Each row is a song on Billboard and each column is an attribute.

We remove songs that appear > 1 time on Billboard and we keep the observation with the maximum amount of weeks on the charts.


```{r}
library = "C:\\Users\\liblabs-user\\Desktop\\song-authorship\\data"
laptop = "not yet"
desktop = "C:\\Users\\Sam\\Desktop\\song authorship\\data"

setwd(desktop)

df <- read.csv(
    paste(desktop, "\\Weekly_data_clean.csv", sep = ""),
    encoding = "UTF-8",
    stringsAsFactors = FALSE)

df[is.na(df$Weeks.on.chart),"Weeks.on.chart"] <- 1

max_week <- df %>% group_by(Artists, Name) %>%
  summarise(Weeks.on.chart = max(Weeks.on.chart, na.rm = TRUE))

#max_week[mapply(is.infinite, max_week)] <- 1

final_df <- merge(x = max_week, y = df, by = c("Artists", "Name", "Weeks.on.chart"), all.x = TRUE)

```

Our current dataframe is in not in a tidy format so we fix that (one word per row). We also remove stop words.

```{r}
reg <- "([^A-Za-z\\d#@']+|'[^A-Za-z\\d#@]+)"

df_words <- final_df %>%
    unnest_tokens(word, Lyrics, token = "regex", pattern = reg, collapse = TRUE) %>%
    filter(!word %in% stop_words$word, 
           str_detect(word, "[a-z]"))

unique_df_words <- df_words %>% distinct(Name, Artists, word, .keep_all = TRUE)

write.csv(df_words, file = "Weekly_data_tokenized.csv")

write.csv(unique_df_words, file = "Weekly_data_tokenized_unique.csv")
```

## Log-odds ratio

The log odds ratio for each word is calculated as

$$\log_2\left(\frac{\frac{\text{# in robotic}}{\text{Total robotic}}}{\frac{\text{# in non-robotic}}{\text{Total non-robotic}}}\right)$$
A higher log odds ratio means the word occurs in more robotic songs than non-robotoc songs.

```{r, fig.width = 8, fig.height = 9, echo = FALSE}
num_words_to_filter = 5

ratios <- unique_df_words %>%
    count(word, Songwriter) %>%
    filter(n > num_words_to_filter) %>%
    spread(Songwriter, n, fill = 0) %>%
    ungroup() %>% #what is this used for?
    mutate_each(funs((. + 1) / sum(. + 1)), -word) %>%
    mutate(logratio = log2(True / False)) %>%
    arrange(desc(logratio))

rbind(ratios %>% top_n(30, logratio), ratios %>% top_n(-30, logratio)) %>%
    mutate(word = reorder(word, logratio)) %>%
    ggplot(aes(word, logratio)) +
    geom_col(show.legend = FALSE) +
    coord_flip()

```

Key takeaways:

- Not very informative, lots of outliers. Let's exclude this in the end.

## Sentiment Analysis

For sentiments, we used the (NRC Emotion Lexicon)[https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm]. We run a Poisson test on each sentiment between robotic and non-robotic songs. The confidence intervals are plotted below:

```{r, echo = FALSE, fig.width = 8, fig.height = 6}
nrc <- sentiments %>%
    filter(lexicon == "nrc") %>%
    dplyr::select(word, sentiment)

sources <- df_words %>%
    group_by(Songwriter) %>%
    mutate(total_words = n()) %>%
    ungroup() %>%
    distinct(Name, Songwriter, total_words)

by_source_sentiment <- df_words %>%
    inner_join(nrc, by = "word") %>%
    count(sentiment, Name) %>%
    ungroup() %>%
    complete(sentiment, Name, fill = list(n = 0)) %>%
    inner_join(sources, "Name") %>%
    group_by(Songwriter, sentiment, total_words) %>%
    summarize(words = sum(n)) %>%
    ungroup()

sentiment_diff <- by_source_sentiment %>%
    group_by(sentiment) %>%
    do(tidy(poisson.test(.$words, .$total_words))) %>%
    ungroup()

# plot
sentiment_diff %>%
    mutate(sentiment = reorder(sentiment, estimate)) %>%
    ggplot(aes(sentiment, estimate)) + 
    geom_errorbar(width = .5, aes(ymin = conf.low, ymax = conf.high)) +
    geom_point(shape = 21, size = 2.5, fill = "white") +
    scale_y_continuous("% change in Robotic relative to non-Robotic",
                       breaks = c(0.6, 0.8, 1, 1.2, 1.4, 1.6),
                       labels = c("-40%", "-20%", "0%", "20%", "40%", "60%")) +
    coord_flip()
```

Key takeaways:

In general, non-Robotic songs utilize less words with sentiments relating to joy, positivity, sadness, negativity, and fear than robotic songs. 

Let's explore which words have the most positive log odds ratio (used in Robotic songs more often than non-robotic) by sentiment:

```{r, echo = FALSE, fig.width = 9, fig.height = 6}
# do we even want this?
ratios <- unique_df_words %>%
    count(word, Songwriter) %>%
    filter(n > num_words_to_filter) %>%
    spread(Songwriter, n, fill = 0) %>%
    ungroup() %>% #what is this used for?
    mutate_each(funs((. + 1) / sum(. + 1)), -word) %>%
    mutate(logratio = log2(True / False)) %>%
    arrange(desc(logratio))

top_and_bottom <- ratios %>%
    inner_join(nrc, by = "word") %>%
    filter(!sentiment %in% c("positive", "negative")) %>%
    mutate(sentiment = reorder(sentiment, -logratio),
           word = reorder(word, -logratio)) %>%
    group_by(sentiment) 
#rbind(ratios %>% top_n(30, logratio), ratios %>% top_n(-30, logratio))
rbind(top_and_bottom %>% top_n(5, logratio), top_and_bottom %>% top_n(-5, logratio)) %>%
    ungroup() %>%
    ggplot(aes(word, logratio, fill = logratio < 0)) +
    facet_wrap(~ sentiment, scales = "free", nrow = 2) +
    geom_bar(stat = "identity") +
    theme(axis.text.x = element_text(angle = 50, hjust = 1)) +
    labs(x = "", y = "Robotic / non-Robotic log ratio") +
    scale_fill_manual(name = "", labels = c("Robotic", "non-Robotic"),
                    values = c("#E69F00", "#56B4E9"))
```

In the positive sentiments:
 - For robotic songs, we can see words such as bless, faith, respect, and law.
  - Possibly showing robotic religious songs use themed words?
 - For non-robotic songs, we can see words such as favorite, finally, and deal
  - Ambiguous, not sure

Curiously, the sentiment trend described above holds for the Pop genre:

```{r, echo = FALSE, fig.width = 8, fig.height = 6}
popdf <- unique_df_words %>% 
    filter(str_detect(Genre, regex("pop", ignore_case = TRUE)))

sources <- popdf %>%
    group_by(Songwriter) %>%
    mutate(total_words = n()) %>%
    ungroup() %>%
    distinct(Name, Songwriter, total_words)

by_source_sentiment <- df_words %>%
    inner_join(nrc, by = "word") %>%
    count(sentiment, Name) %>%
    ungroup() %>%
    complete(sentiment, Name, fill = list(n = 0)) %>%
    inner_join(sources, "Name") %>%
    group_by(Songwriter, sentiment, total_words) %>%
    summarize(words = sum(n)) %>%
    ungroup()

sentiment_diff <- by_source_sentiment %>%
    group_by(sentiment) %>%
    do(tidy(poisson.test(.$words, .$total_words))) %>%
    ungroup()

# plot
sentiment_diff %>%
    mutate(sentiment = reorder(sentiment, estimate)) %>%
    ggplot(aes(sentiment, estimate)) + 
    geom_errorbar(width = .5, aes(ymin = conf.low, ymax = conf.high)) +
    geom_point(shape = 21, size = 2.5, fill = "white") +
    scale_y_continuous("% change in Robotic relative to non-Robotic",
                       breaks = c(0.6, 0.8, 1, 1.2, 1.4, 1.6),
                       labels = c("-40%", "-20%", "0%", "20%", "40%", "60%")) +
    coord_flip()
```

And the Rap genre:

```{r, echo = FALSE, fig.width = 8, fig.height = 6}
rapdf <- unique_df_words %>% 
    filter(str_detect(Genre, regex("rap", ignore_case = TRUE)))

sources <- rapdf %>%
    group_by(Songwriter) %>%
    mutate(total_words = n()) %>%
    ungroup() %>%
    distinct(Name, Songwriter, total_words)

by_source_sentiment <- df_words %>%
    inner_join(nrc, by = "word") %>%
    count(sentiment, Name) %>%
    ungroup() %>%
    complete(sentiment, Name, fill = list(n = 0)) %>%
    inner_join(sources, "Name") %>%
    group_by(Songwriter, sentiment, total_words) %>%
    summarize(words = sum(n)) %>%
    ungroup()

sentiment_diff <- by_source_sentiment %>%
    group_by(sentiment) %>%
    do(tidy(poisson.test(.$words, .$total_words))) %>%
    ungroup()

# plot
sentiment_diff %>%
    mutate(sentiment = reorder(sentiment, estimate)) %>%
    ggplot(aes(sentiment, estimate)) + 
    geom_errorbar(width = .5, aes(ymin = conf.low, ymax = conf.high)) +
    geom_point(shape = 21, size = 2.5, fill = "white") +
    scale_y_continuous("% change in Robotic relative to non-Robotic",
                       breaks = c(0.6, 0.8, 1, 1.2, 1.4, 1.6),
                       labels = c("-40%", "-20%", "0%", "20%", "40%", "60%")) +
    coord_flip()
```

This means that even though non-robotic songs use less words relating to joy, positivity, sadness, negativity, and fear than robotic songs, the fact that this trend is seen across Genre as well implies robotic or not may only be a correlation with respect to sentiment differences.


## Latent Dirichlet Allocation

To further explore our dataset for hidden structure, we applied Latent Dirichlet Allocation. We start with two topics. Below is a visualization of words that are most likely to be generated from the respective topic (terms with highest $\beta$):

```{r, fig.width = 8, fig.height = 9, echo = FALSE}
word_counts <- df_words %>%
    count(Name, word, sort = TRUE) %>%
    filter(n > num_words_to_filter) %>%
    ungroup() # do we need this?
    
word_count_matrix <- word_counts %>% cast_dtm(Name, word, n)

# create LDA object
songs_lda <- LDA(word_count_matrix, k = 2, control = list(seed = 0))
topics <- tidy(songs_lda, matrix = "beta")
    
# visualize
top_terms <- topics %>%
    group_by(topic) %>%
    top_n(40, beta) %>%
    ungroup() %>%
    arrange(topic, -beta)
    
top_terms %>%
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") + # partition by topic
    coord_flip()
```

Key takeaways:

- Words most likely to be generated from topic 1 include love, yeah, baby, wanna, la, and ooh. These seem to originate from pop songs.
- In contrast, words most likely to be generated from topic 2 include many expletives, particularly ones in rap songs. 

This leads us to believe LDA accurately captures a difference between the language used in pop songs and rap songs.

Below is a visualization that measures log-odds between the two topics. It tells the same story.

```{r, echo = FALSE, fig.width = 8, fig.height = 9}

beta_spread <- topics %>%
    mutate(topic = paste0("topic", topic)) %>% # adds topic to each number   
    spread(topic, beta) %>% # key, values w/ values for each var
    filter(topic1 > .005 | topic2 > .005) %>%
    mutate(log_ratio = log2(topic2 / topic1)) %>%
    #filter(abs(log_ratio) < 50) %>%
    arrange(-log_ratio)

# plot
beta_spread %>%
    mutate(term = reorder(term, log_ratio)) %>%
    ggplot(aes(term, log_ratio)) + 
    geom_col(show.legend = FALSE) +
    coord_flip()

```

## Principal Component Analysis

Let's dive deeper into the lyrical content.

```{r}
# one entry for each song-word
each_song <- unique_df_words %>%
    count(word, Name, Artists, Songwriter)

num_songs <- table(each_song$word)

# One entry for each artist-word
each_artist <- unique_df_words %>%
    count(word, Artists)

num_artists <- table(each_artist$word)

good_words <- names(num_songs[num_songs > 20])
    
word_count_matrix <- each_song %>% filter(word %in% good_words) %>% cast_dtm(Name, word, n)

robotic <- each_song %>% filter(word %in% good_words) %>% distinct(Name, .keep_all = TRUE) %>% select(Songwriter) %>% unlist()

#word_counts <- df_words %>%
#    count(Name, word, sort = TRUE) %>%
#    filter(n > num_words_to_filter) %>%
#    ungroup() # do we need this?

#word_count_matrix <- word_counts %>% cast_dtm(Name, word, n)

```


## K-means


