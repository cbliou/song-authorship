knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#install.packages("tidytext")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("tm")
#install.packages("topicmodels")
#install.packages("broom")
#install.packages("caret")
#install.packages("broom")
#install.packages("randomForest")
#install.packages("e1071")
library(purrr)
library(magrittr)
library(tidyr)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
library(tm)
library(topicmodels)
library(broom)
library(e1071)
library(caret)
library(randomForest)
# read in data
reg <- "([^A-Za-z\\d#@']+|'[^A-Za-z\\d#@]+)"
df <- read.csv(
"..\\..\\data\\Weekly_data_top_week.csv",
encoding = "UTF-8",
stringsAsFactors = FALSE)
df_words <- read.csv(
"..\\..\\data\\Weekly_data_tokenized.csv",
encoding = "UTF-8",
stringsAsFactors = FALSE)
unique_df_words <- read.csv(
"..\\..\\data\\Weekly_data_tokenized_unique.csv",
encoding = "UTF-8",
stringsAsFactors = FALSE)
metrics <- read.csv(
"..\\..\\data\\Song_Complexity.csv",
encoding = "UTF-8",
stringsAsFactors = FALSE
)
df <- merge(x = df, y = metrics, by = c("X"), all.x = TRUE)
colnames(df)[colnames(df) == "Songwriter.x"] <- "Songwriter"
#final_df <- merge(x = max_week, y = df, by = c("Artists", "Name", "Weeks.on.chart"), all.x = TRUE)
num_words_to_filter = 5
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
sources <- unique_df_words %>%
group_by(Songwriter) %>%
mutate(total_words = n()) %>%
ungroup() %>%
distinct(Name, Songwriter, total_words)
by_source_sentiment <- unique_df_words %>%
inner_join(nrc, by = "word") %>%
count(sentiment, Name) %>%
ungroup() %>%
complete(sentiment, Name, fill = list(n = 0)) %>%
inner_join(sources, "Name") %>%
group_by(Songwriter, sentiment, total_words) %>%
summarize(words = sum(n)) %>%
ungroup()
sentiment_diff <- by_source_sentiment %>%
group_by(sentiment) %>%
do(tidy(poisson.test(.$words, .$total_words))) #%>%
#ungroup() %>%
#mutate(sentiment = reorder(sentiment, estimate),
#       subset = "All genres")
# plot
sentiment_diff  %>%
ggplot(aes(sentiment, estimate)) +
geom_errorbar(width = .5, aes(ymin = conf.low, ymax = conf.high)) +
geom_point(shape = 21, size = 2.5, fill = "white") +
scale_y_continuous("% change in Robotic relative to non-Robotic",
breaks = c(0.6, 0.8, 1, 1.2, 1.4, 1.6),
labels = c("-40%", "-20%", "0%", "20%", "40%", "60%")) +
coord_flip()
sentiment_diff <- by_source_sentiment %>%
group_by(sentiment) #%>%
poisson.test(sentiment_diff, words, total_words)
?poisson.test
sentiment_diff
poisson.test(sentiment_diff$words)
sentiment_diff
sentiment_diff[sentiment_diff$Songwriter = FALSE]
sentiment_diff[sentiment_diff$Songwriter == FALSE]
sentiment_diff$Songwriter == FALSE
sentiment_diff$Songwriter == "False"
sentiment_diff[sentiment_diff$Songwriter == "False"]
sentiment_diff[which(sentiment_diff$Songwriter == "False")]
sentiment_diff[which(sentiment_diff$Songwriter == "False"),]
sentiment_diff[which(sentiment_diff$Songwriter == "False"),]$words
sentiment_diff[which(sentiment_diff$Songwriter == "False"),]$words
sentiment_diff
poisson.test(sentiment_diff[which(sentiment_diff$Songwriter == "False"),]$words, sentiment_diff[which(sentiment_diff$Songwriter == "True"),]$words)
tidy(poisson.test(sentiment_diff[which(sentiment_diff$Songwriter == "False"),]$words, sentiment_diff[which(sentiment_diff$Songwriter == "True"),]$words))
poisson.test(sentiment_diff$words, sentiment_diff$total_words)
poisson.test(c(11, 6+8+7), c(800, 1083+1050+878))
poisson.test(c(sentiment_diff$words, sentiment_diff$total_words))
poisson.test(sum(sentiment_diff$words), sentiment_diff$total_words)
poisson.test(sum(sentiment_diff$words), length(sentiment_diff$total_words))
apply(sentiment_diff, 1, poisson.test, x = .$words, T = total_words)
apply(sentiment_diff, 1, poisson.test, x = sentiment_diff$words, T = sentiment_diff$total_words)
apply(sentiment_diff, 1, FUN=poisson.test, x = sentiment_diff$words, T = sentiment_diff$total_words)
apply(sentiment_diff, 1, FUN=poisson.test, x = words, T = total_words)
apply(sentiment_diff, 1, FUN=poisson.test, x = .$words, T = .$total_words)
apply(sentiment_diff, 1, FUN=poisson.test, x = sentiment_diff[words], T = sentiment_diff[total_words])
apply(sentiment_diff, 1, FUN=poisson.test, x = sentiment_diff["words"], T = sentiment_diff["total_words"])
sentiment_diff["words"]
?apply
install.packages("tidyverse")
install.packages("tidytext")
library(magrittr)
library(tidyverse)
library(tidytext)
install.packages("tidytext")
#install.packages("tidyverse")
#install.packages("tidytext")
library(magrittr)
library(tidyverse)
library(tidytext)
df <- read.csv("..\\..\\data\\Weekly_data_clean.csv",
encoding = "UTF-8",
stringsAsFactors = FALSE)
df[is.na(df$Weeks.on.chart),"Weeks.on.chart"] <- 1
df[is.na(df$Peak.position), "Peak.position"] <- df[is.na(df$Peak.position), "Weekly.rank"]
max_week <- df %>% group_by(Artists, Name) %>%
summarise(Weeks.on.chart = max(Weeks.on.chart, na.rm = TRUE))
final_df <- merge(x = max_week, y = df, by = c("Artists", "Name", "Weeks.on.chart"), all.x = TRUE)
final_df$ID <- seq(1:nrow(final_df))
write.csv(final_df, file = "..\\..\\data\\Weekly_data_top_week.csv")
reg <- "([^A-Za-z\\d#@']+|'[^A-Za-z\\d#@]+)"
df_words <- final_df %>%
unnest_tokens(word, Lyrics, token = "regex", pattern = reg, collapse = TRUE) %>%
mutate(
word = gsub("([A-z])\\1{2,}", '\\1\\1', word), # ayyyy -> ayy
word = gsub("([A-z])'[A-z]+", '\\1', word),
word = gsub("[^A-z]", '', word)
) %>%
mutate(
Artists = str_to_lower(gsub('([A-z])([A-Z][a-z])|([a-z])([A-Z])', '\\1, \\2', Artists)),
Writing.Credits = str_to_lower(Writing.Credits)
) %>%
filter(!word %in% stop_words$word, str_detect(word, "[a-z]"))
unique_df_words <- df_words %>% distinct(Name, Artists, word, .keep_all = TRUE)
write.csv(df_words, file = "..\\..\\data\\Weekly_data_tokenized.csv")
write.csv(unique_df_words, "..\\..\\data\\Weekly_data_tokenized_unique.csv")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
#install.packages("tidytext")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("tm")
#install.packages("topicmodels")
#install.packages("broom")
#install.packages("caret")
#install.packages("broom")
#install.packages("randomForest")
#install.packages("e1071")
#install.packages("tidyverse")
require(tidyverse)
require(tm)
require(topicmodels)
require(tidytext)
require(SnowballC)
df <- read.csv("..\\..\\data\\Weekly_data_top_week.csv",
encoding = "UTF-8",
stringsAsFactors = FALSE)
reg <- "([^A-Za-z\\d#@']+|'[^A-Za-z\\d#@]+)"
df_words <- df %>%
unnest_tokens(word, Lyrics, token = "regex", pattern = reg, collapse = TRUE)
df_words_unique <- df_words %>%
group_by(Artists, Name, Peak.position, Weeks.on.chart, Date, Genre, Writing.Credits, Songwriter) %>%
count(word) %>%
ungroup() %>%
group_by(Artists, Name, word, n, Songwriter, Writing.Credits, Genre) %>%
summarize_at(vars(Peak.position, Weeks.on.chart), funs(min(., na.rm = TRUE), max(., na.rm = TRUE))) %>% ungroup() %>%
select(-Weeks.on.chart_min, -Peak.position_max)
load(system.file("words", "english.RData", package = "SnowballC"))
each_song <- df_words_unique %>% mutate(
word = gsub("([A-z])\\1{2,}", '\\1\\1', word),
word = gsub("([A-z])'[A-z]+", '\\1', word),
word = gsub("[^A-z]", '', word),
word = gsub("\\s+", "", word)
) %>%
mutate(
Artists = str_to_lower(gsub('([A-z])([A-Z][a-z])|([a-z])([A-Z])', '\\1, \\2', Artists)),
Writing.Credits = str_to_lower(Writing.Credits),
Contributors = str_split(str_to_lower(paste(Artists, Writing.Credits, sep = ", ")), ", ")
)
each_song$Contributors = sapply(each_song$Contributors, function(x) toString(unique(unlist(x))))
each_song$Contributors = gsub("\n", "", each_song$Contributors, fixed = TRUE)
all_words <- unique(each_song$word)
num_songs <- table(each_song$word)
word_rarity <- -log(num_songs/max(num_songs))
word_length <- sapply(all_words, str_length)
each_song_once <- each_song %>% mutate(
rarity = word_rarity[word],
word_len = word_length[word]
) %>% na.omit() %>%
group_by(Name, Artists, Songwriter) %>%
summarise_at(vars(rarity, word_len), funs(max) )
unique_words <- each_song %>% group_by(Name, Artists) %>% count()
idf <- log(nrow(df) / num_songs)
tf_idf_score <- each_song %>%
mutate(wordtfidf = as.numeric(n * idf[word])) %>%
group_by(Artists, Name) %>%
summarize_at(vars(wordtfidf), sum, na.rm = TRUE) %>%
left_join(unique_words) %>%
mutate(
tf_idf_complexity = wordtfidf / nn
)
song_complexity <- each_song %>%  mutate(
word_length = str_length(word),
word_rare = word_rarity[word],
is_profanity = word %in% c("fuck", "shit", "bitch")
) %>% group_by(Name, Artists, Songwriter) %>%
summarize(
Total_Words = sum(n),
Unique_Words = length(n),
diversity = Unique_Words/Total_Words,
mean_word_rarity = mean(word_rare, na.rm = TRUE),
median_word_rarity = median(word_rare, na.rm = TRUE),
mean_word_length = mean(word_length, na.rm = TRUE),
median_word_length = median(word_length, na.rm = TRUE),
num_profanity = sum(is_profanity)
) %>%
left_join(tf_idf_score)
write.csv(song_complexity, "..\\..\\data\\Song_Complexity.csv")
num_words_to_filter = 5
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
sources <- unique_df_words %>%
group_by(Songwriter) %>%
mutate(total_words = n()) %>%
ungroup() %>%
distinct(Name, Songwriter, total_words)
by_source_sentiment <- unique_df_words %>%
inner_join(nrc, by = "word") %>%
count(sentiment, Name) %>%
ungroup() %>%
complete(sentiment, Name, fill = list(n = 0)) %>%
inner_join(sources, "Name") %>%
group_by(Songwriter, sentiment, total_words) %>%
summarize(words = sum(n)) %>%
ungroup()
sentiment_diff <- by_source_sentiment %>%
group_by(sentiment) %>%
do(tidy(poisson.test(.$words, .$total_words))) %>%
ungroup() %>%
mutate(sentiment = reorder(sentiment, estimate),
subset = "All genres")
#apply(sentiment_diff, 1, FUN=poisson.test, x = sentiment_diff["words"], T = sentiment_diff["total_words"])
# plot
sentiment_diff  %>%
ggplot(aes(sentiment, estimate)) +
geom_errorbar(width = .5, aes(ymin = conf.low, ymax = conf.high)) +
geom_point(shape = 21, size = 2.5, fill = "white") +
scale_y_continuous("% change in Robotic relative to non-Robotic",
breaks = c(0.6, 0.8, 1, 1.2, 1.4, 1.6),
labels = c("-40%", "-20%", "0%", "20%", "40%", "60%")) +
coord_flip()
