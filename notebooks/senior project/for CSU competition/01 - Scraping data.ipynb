{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import html2text as ht\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import traceback\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Billboard for song titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTracker:\n",
    "    \n",
    "    days = {1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30, \n",
    "            7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "    \n",
    "    def __init__(self, year = None, month = None, day = None):\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.day = day\n",
    "        \n",
    "    def previous_week(self):\n",
    "        \n",
    "        if (self.year == 1958) and (self.month == 8) and (0 < self.day <= 7):\n",
    "            return\n",
    "        \n",
    "        # if move to previous month\n",
    "        if self.day - 7 <= 0:\n",
    "            \n",
    "            if self.month != 1:\n",
    "                \n",
    "                self.month -= 1\n",
    "                self.day += self.days[self.month] - 7\n",
    "            \n",
    "            # if move to previous year\n",
    "            else:\n",
    "                \n",
    "                self.year -= 1\n",
    "                self.month = 12\n",
    "                self.day += self.days[self.month] - 7\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            self.day -= 7\n",
    "            \n",
    "    def as_date(self):\n",
    "        \n",
    "        return \"%04d-%02d-%02d\" % (self.year, self.month, self.day)\n",
    "        \n",
    "        \n",
    "class Song:\n",
    "    \n",
    "    def __init__(self, artist, name, rank, peakpos, weeksonchart, date):\n",
    "        self.artist = artist\n",
    "        self.name = name\n",
    "        self.rank = rank\n",
    "        self.peakpos = peakpos\n",
    "        self.weeksonchart = weeksonchart\n",
    "        self.date = date\n",
    "        \n",
    "    def get_artist(self):\n",
    "        return self.artist\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_rank(self):\n",
    "        return self.rank\n",
    "    \n",
    "    def get_peak_pos(self):\n",
    "        return self.peakpos\n",
    "    \n",
    "    def get_weeks_on_chart(self):\n",
    "        return self.weeksonchart\n",
    "    \n",
    "    def get_date(self):\n",
    "        return self.date\n",
    "    \n",
    "    def list_form(self):\n",
    "        return [self.artist, self.name, self.rank, self.peakpos,\n",
    "                self.weeksonchart, self.date]\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"\\n\".join([str(x) for x in [self.artist, self.name,\n",
    "                                          self.rank, self.peakpos,\n",
    "                                          self.weeksonchart, self.date]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    bad = {\"\\\\\\\\n\": \"\\n\", \n",
    "           \"\\n+\": \"\\n\", \n",
    "           \"\\n\": \" - \",\n",
    "           \"\\[\\]\\(.{0,}?\\)\": \"\",\n",
    "           \"\\[Play\\]\\(.{0,}?\\)\": \"\",\n",
    "           \"\\[\\s{0,5}-\\s{0,5}Song\\s{0,5}-\\s{0,5}Lyrics\\s{0,5}-\\s{0,5}\\]\\(.{0,}?\\)\": \"\"}\n",
    "\n",
    "    for x in bad:\n",
    "        text = re.sub(x, bad[x], text, flags = re.I | re.S)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def clean_line(text):\n",
    "    repl = {\"weeks at no. 1\": \"\",\n",
    "            \"(-\\s{1,4}!)+\": \"\",\n",
    "            \"(?<![A-z])! -\": \"\",\n",
    "            \"_\": \"\",\n",
    "            \"\\[\\s-\": \"\", \n",
    "            \"-\\s\\]\": \"\",\n",
    "            \"\\[.{0,}?\\]|\\(.{0,}?\\)\": \"\",\n",
    "            \"\\s+\": \" \",\n",
    "            \"(-\\s{1,5})+\": \"- \",}    \n",
    "    \n",
    "    for x in repl:\n",
    "        text = re.sub(x, repl[x], text, flags = re.I | re.S)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_by_week(weeks = 100):\n",
    "    \n",
    "    #filler = [\" and \", \" featuring \", \" & \", \" x \", \" / \"]\n",
    "    namesub = {\"f\\*\\*k\": \"fuck\", \"s\\*\\*t\": \"shit\"}\n",
    "    path = \"https://www.billboard.com/charts/hot-100\"\n",
    "    curdate = DateTracker(year = 2018, month = 8, day = 11)\n",
    "    songs = []\n",
    "\n",
    "    for j in range(weeks):\n",
    "        \n",
    "        page = requests.get(path + \"/\" + curdate.as_date())\n",
    "        if j % 20 == 0:\n",
    "            print(\"We are on week {}, it is {}\".format(j, curdate.as_date()))\n",
    "\n",
    "        data = ht.html2text(str(page.content))\n",
    "        data = clean_text(data)\n",
    "        data = re.split(\"date search |in performance - |on chart - \", data, flags = re.I)[1:]\n",
    "\n",
    "        #first one\n",
    "        weeksoc = int(re.search(\"[0-9]{0,1}\\s-\\sweeks\", \n",
    "                                re.sub(\"weeks at no. 1\", \"\", data[0], flags = re.I | re.S),\n",
    "                                flags = re.I | re.S).group()[:2])\n",
    "        tmp = clean_line(data[1]).strip().split(\"-\")\n",
    "        name = tmp[0].strip()\n",
    "        for k in namesub:\n",
    "            name = re.sub(k, namesub[k], name, flags = re.I | re.S)\n",
    "        artist = tmp[1].strip()\n",
    "        # for k in filler:\n",
    "        #     artist = re.sub(k, \", \", artist, flags = re.I | re.S)\n",
    "\n",
    "        songs.append(Song(artist = artist, name = name, rank = 1,\n",
    "                          peakpos = 1, weeksonchart = weeksoc, \n",
    "                          date = curdate.as_date()))\n",
    "\n",
    "\n",
    "        #everything else (2 - 100)\n",
    "        for i in data[2:]:\n",
    "            #we know we have a rank\n",
    "            if re.match(\"^[0-9]{0,3}\", i.strip()).group() != \"\":\n",
    "                i = clean_line(i)\n",
    "                tmp = i.split(\"-\")\n",
    "                rank = tmp[0].strip()\n",
    "                name = tmp[1].strip()\n",
    "                for k in namesub:\n",
    "                    name = re.sub(k, namesub[k], name, flags = re.I | re.S)\n",
    "                artist = tmp[2].strip()\n",
    "                # for k in filler:\n",
    "                #     artist = re.sub(k, \", \", artist, flags = re.I | re.S)\n",
    "                    \n",
    "                #if these are empty they're debuts!\n",
    "                try:\n",
    "                    peakpos = int(re.search(\"[0-9]{0,3}\\s-\\speak position\", i, flags = re.I | re.S).group().split(\" \")[0])\n",
    "                except AttributeError:\n",
    "                    peakpos = \"\"\n",
    "                try:\n",
    "                    weeksoc = int(re.search(\"[0-9]{0,3}\\s-\\sweeks\", i, flags = re.I | re.S).group().split(\" \")[0])\n",
    "                except AttributeError:\n",
    "                    weeksoc = \"\"\n",
    "\n",
    "                songs.append(Song(artist = artist, name = name, rank = rank,\n",
    "                                  peakpos = peakpos, weeksonchart = weeksoc,\n",
    "                                  date = curdate.as_date()))\n",
    "\n",
    "        curdate.previous_week()\n",
    "        \n",
    "    return songs, curdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on week 0, it is 2018-08-11\n",
      "We are on week 20, it is 2018-03-24\n",
      "We are on week 40, it is 2017-11-04\n",
      "We are on week 60, it is 2017-06-17\n",
      "We are on week 80, it is 2017-01-28\n",
      "We are on week 100, it is 2016-09-10\n",
      "We are on week 120, it is 2016-04-23\n",
      "We are on week 140, it is 2015-12-04\n",
      "We are on week 160, it is 2015-07-17\n",
      "We are on week 180, it is 2015-02-27\n",
      "We are on week 200, it is 2014-10-10\n",
      "We are on week 220, it is 2014-05-23\n",
      "We are on week 240, it is 2014-01-03\n",
      "We are on week 260, it is 2013-08-16\n",
      "We are on week 280, it is 2013-03-29\n",
      "We are on week 300, it is 2012-11-09\n",
      "We are on week 320, it is 2012-06-22\n",
      "We are on week 340, it is 2012-02-02\n",
      "We are on week 360, it is 2011-09-15\n",
      "We are on week 380, it is 2011-04-28\n",
      "We are on week 400, it is 2010-12-09\n",
      "We are on week 420, it is 2010-07-22\n",
      "We are on week 440, it is 2010-03-04\n",
      "We are on week 460, it is 2009-10-15\n",
      "We are on week 480, it is 2009-05-28\n"
     ]
    }
   ],
   "source": [
    "songs, curdate = get_songs_by_week(weeks = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = np.array([x.list_form() for x in songs])\n",
    "df = pd.DataFrame({\n",
    "    \"Artists\": prep[:, 0],\n",
    "    \"Name\": prep[:, 1],\n",
    "    \"Weekly rank\": prep[:, 2],\n",
    "    \"Peak position\": prep[:, 3],\n",
    "    \"Weeks on chart\": prep[:, 4],\n",
    "    \"Week\": prep[:, 5]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"..//..//data//Weekly_ranks.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..//..//data//Weekly_ranks.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Genius for lyrics, genre, etc.\n",
    "\n",
    "\n",
    "Song name\n",
    "\n",
    "Artist/Group\n",
    "\n",
    "Weekly rank \n",
    "\n",
    "Peak rank\n",
    "\n",
    "Year published\n",
    "\n",
    "Genre\n",
    "\n",
    "Writing Credits\n",
    "\n",
    "Lyrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(19, 23), match='a$aP'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"A\\$AP\", \"HaNDGUN by YG (Ft. a$aP Rocky)\", flags = re.I | re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_lyric_link(df.iloc[97][\"Artists\"], df.iloc[97][\"Name\"], debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyric_link(artists, name, both = False, debug = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the link of the song name given artists + name of the song\n",
    "    \"\"\"\n",
    "    \n",
    "    client_token = \"BrGsH3KoiMzSyCUClF4-TyzjrNfQfrr2-Q9bfK6Bhum1fquRgVf0rn-Pq6mr9Uyc\"\n",
    "    headers = {\"Authorization\": \"Bearer \" + client_token}\n",
    "    link = \"https://api.genius.com/search?q=\"\n",
    "    space = \"%20\"\n",
    "    \n",
    "    #this could prove disastrous, double check it...\n",
    "    # update: yes it did, just replace accents.\n",
    "    name_repl = {\"Beyonce\": \"Beyoncé\", \n",
    "                 \"Amine\": \"Aminé\",\n",
    "                 \"D.R.A.M.\": \"DRAM\",\n",
    "                 \"$ign\": \"\\$ign\"}\n",
    "    repl = {\n",
    "        \"a|á|ạ|à|ả|ã|ă|ắ|ặ|ằ|ẳ|ẵ|â|ấ|ậ|ầ|ẩ|ẫ\": \"a\",\n",
    "        \"é|ẹ|è|ẻ|ẽ|ê|ế|ệ|ề|ể|ễ|ë\": \"e\",\n",
    "        \"í|ị|ì|ỉ|ĩ\": \"i\",\n",
    "        \"ó|ọ|ò|ỏ|õ|ô|ố|ộ|ồ|ổ|ỗ|ơ|ớ|ợ|ờ|ỡ\": \"o\",\n",
    "        \"ú|ụ|ù|ủ|ũ|ư|ứ|ự|ừ|ử|ữ\": \"u\",\n",
    "        \"ý|ỵ|ỳ|ỷ|ỹ\": \"y\"\n",
    "    }\n",
    "    artistregex = {\n",
    "        \"\\$\": \"\\\\\\\\$\"\n",
    "    }\n",
    "    filler = [\" and \", \" featuring \", \" & \", \" x \", \" / \"]\n",
    "\n",
    "    artiststmp = re.sub(\",\", \"\", artists)\n",
    "    name = re.sub(\",\", \"\", name)\n",
    "    if both:\n",
    "        page = requests.get(link + re.sub(\" \", space, name) +\n",
    "                            space + re.sub(\" \", space, artiststmp), headers = headers)\n",
    "    else:\n",
    "        page = requests.get(link + re.sub(\" \", space, name), headers = headers)\n",
    "        \n",
    "    # now that we searched, remove filler words that may not appear\n",
    "    # in actual song title\n",
    "    page = json.loads(page.content)[\"response\"][\"hits\"]\n",
    "    for i in filler:\n",
    "        artiststmp = re.sub(i, \" \", artiststmp, flags = re.I | re.S)\n",
    "    check = [re.sub(\",\", \"\", x) for x in artiststmp.split(\" \") + name.split(\" \") if x not in string.punctuation]\n",
    "\n",
    "\n",
    "    # fix artist tokens to be used in re.search\n",
    "    for i in artistregex:\n",
    "        for j in range(len(check)):\n",
    "            check[j] = re.sub(i, artistregex[i], check[j], flags = re.I | re.S)\n",
    "            \n",
    "    if debug:\n",
    "        print(check)    \n",
    "        \n",
    "    top = []\n",
    "\n",
    "    \n",
    "    \n",
    "    if len(page) == 1:\n",
    "        return page[0][\"result\"][\"path\"]\n",
    "    else:\n",
    "        for i in range(len(page)):\n",
    "            c = 0\n",
    "            \n",
    "            # remove accents from title\n",
    "            title = page[i][\"result\"][\"full_title\"]\n",
    "            for j in repl:\n",
    "                title = re.sub(j, repl[j], title, flags = re.I | re.S)\n",
    "\n",
    "            if debug:\n",
    "                print(title)\n",
    "                \n",
    "            # check if every artist + name token in the full title\n",
    "            for j in check:\n",
    "                if re.search(j, title, flags = re.I | re.S) != None:\n",
    "                    c += 1\n",
    "            if c == len(check):\n",
    "                try:\n",
    "                    if page[i][\"result\"][\"stats\"][\"pageviews\"] > 0:\n",
    "                        return page[i][\"result\"][\"path\"]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "        \n",
    "    #if we are here, search failed. now we include the artists as well\n",
    "    if both == False:\n",
    "        return get_lyric_link(artiststmp, name, True)\n",
    "    \n",
    "    top = []\n",
    "    \n",
    "    #if here, find most popular song\n",
    "    #print()\n",
    "    #print(\"hopefully we never see this message.\")\n",
    "    #print(artiststmp, name)\n",
    "    for j in range(len(page)):\n",
    "        try:\n",
    "            top.append(page[i][\"result\"][\"stats\"][\"pageviews\"])\n",
    "        except Exception:\n",
    "            top.append(-1)\n",
    "    #print(page[np.argmax(top)][\"result\"][\"path\"])\n",
    "    #print()\n",
    "    return page[np.argmax(top)][\"result\"][\"path\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape_lyrics(row, snip):\n",
    "    \n",
    "    # fix artist names w/ these\n",
    "    repl = {\n",
    "        \"á|ạ|à|ả|ã|ă|ắ|ặ|ằ|ẳ|ẵ|â|ấ|ậ|ầ|ẩ|ẫ\": \"a\",\n",
    "        \"é|ẹ|è|ẻ|ẽ|ê|ế|ệ|ề|ể|ễ|ë\": \"e\",\n",
    "        \"í|ị|ì|ỉ|ĩ\": \"i\",\n",
    "        \"ó|ọ|ò|ỏ|õ|ô|ố|ộ|ồ|ổ|ỗ|ơ|ớ|ợ|ờ|ỡ\": \"o\",\n",
    "        \"ú|ụ|ù|ủ|ũ|ư|ứ|ự|ừ|ử|ữ\": \"u\",\n",
    "        \"ý|ỵ|ỳ|ỷ|ỹ\": \"y\",\n",
    "        \"\\$\": \"\\\\\\\\$\"\n",
    "    }\n",
    "    \n",
    "    base_link = \"https://genius.com\"\n",
    "    content = requests.get(base_link + snip).content\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    # get genre\n",
    "    \n",
    "    \n",
    "    genre_sub = {\"\\\"\": \" \", \n",
    "                 \"genius\": \"\", \n",
    "                 \"\\s+,\": \",\",\n",
    "                 \"&quot;\": \"\",\n",
    "                 \"&amp\": \"&\",\n",
    "                 \"&:\": \"&\"}\n",
    "    genre_regex = \"genres&quot;:\\[.+?\\]\"\n",
    "        \n",
    "    try:\n",
    "        genre = re.search(\"\\[.+?\\]\", re.search(genre_regex, str(content), flags = re.I | re.S).group()).group()[1:-1]\n",
    "        for k in genre_sub:\n",
    "            genre = re.sub(k, genre_sub[k], genre, flags = re.I)\n",
    "    except AttributeError:\n",
    "        genre = \"\"\n",
    "        \n",
    "    data = BeautifulSoup(content, \"lxml\").get_text()\n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    # get all writers (expensive search)\n",
    "    \n",
    "    meta_data = content.decode(\"utf8\")\n",
    "    \n",
    "    start_meta_regex = \"verified_lyrics_by.*?writer_artists&quot\"\n",
    "    stop_meta_regex = \"itemprop=\\\"page_data\\\"\"\n",
    "    write_regex = \"https://genius.com/artists/[^&]*\"\n",
    "\n",
    "    start = re.search(start_meta_regex, meta_data, flags = re.I | re.S).end()\n",
    "    stop = re.search(stop_meta_regex, meta_data, flags = re.I | re.S).end()\n",
    "    meta_data = meta_data[start:stop]\n",
    "\n",
    "    write_links = re.findall(write_regex, meta_data)\n",
    "    write = [re.sub(\"https://genius.com/artists/\", \"\", x) for x in write_links]\n",
    "    write = \", \".join([re.sub(\"-\", \" \", x) for x in write])\n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    \n",
    "    #subset data to search for lyrics\n",
    "    \n",
    "    genre_sub = {\"\\\"\": \" \", \"genius\": \"\", \"\\s+,\": \",\"}\n",
    "    lyric_regex = row[\"Name\"] + \".{0,20}?Lyrics.+?More on Genius\"\n",
    "    genre_regex = \"genres\\\":\\[.+?\\]\"\n",
    "    track_info_regex = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?remixed by\"\n",
    "    track_info_regex2 = \"\\\"{}\".format(row[\"Name\"]) + \".{0,20}?\\\".{0,20}?track info.+?cover by\"\n",
    "    date_regex = \"release date.{0,15}?20[0-9][0-9]\"\n",
    "    write_regex = \"Written By\\n+.+?\\n\"\n",
    "    \n",
    "    \n",
    "    # get lyrics\n",
    "    #print(data)\n",
    "    data = data[re.search(base_link + snip, data).end():]\n",
    "    for i in repl:\n",
    "        data = re.sub(i, repl[i], data, flags = re.I | re.S)\n",
    "    \n",
    "    lyrics = re.search(lyric_regex, data, flags = re.I | re.S).group()[:-15]\n",
    "    \n",
    "    #get date\n",
    "    try:\n",
    "        date = re.split(\"\\n+\", re.search(date_regex, data, flags = re.I | re.S).group())[-1]\n",
    "    except AttributeError:\n",
    "        date = \"\"\n",
    "        \n",
    "    return date, genre, write, lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are 0.0% done\n",
      "We are 1.0101% done\n",
      "We are 2.0202% done\n",
      "We are 3.0303% done\n",
      "We are 4.0404% done\n",
      "We are 5.0505% done\n",
      "We are 6.0606% done\n",
      "We are 7.0707% done\n",
      "We are 8.0808% done\n",
      "We are 9.0909% done\n",
      "We are 10.101% done\n",
      "We are 11.1111% done\n",
      "We are 12.1212% done\n",
      "We are 13.1313% done\n",
      "We are 14.1414% done\n",
      "We are 15.1515% done\n",
      "We are 16.1616% done\n",
      "We are 17.1717% done\n",
      "We are 18.1818% done\n",
      "We are 20.202% done\n",
      "We are 21.2121% done\n",
      "We are 22.2222% done\n",
      "We are 23.2323% done\n",
      "We are 24.2424% done\n",
      "We are 25.2525% done\n",
      "We are 26.2626% done\n",
      "We are 27.2727% done\n",
      "We are 28.2828% done\n",
      "We are 29.2929% done\n",
      "We are 30.303% done\n",
      "We are 31.3131% done\n",
      "We are 32.3232% done\n",
      "We are 33.3333% done\n",
      "We are 34.3434% done\n",
      "We are 35.3535% done\n",
      "We are 36.3636% done\n",
      "We are 37.3737% done\n",
      "We are 38.3838% done\n",
      "We are 39.3939% done\n",
      "We are 40.404% done\n",
      "We are 41.4141% done\n",
      "We are 42.4242% done\n",
      "We are 43.4343% done\n",
      "We are 44.4444% done\n",
      "We are 45.4545% done\n",
      "We are 46.4646% done\n",
      "We are 47.4747% done\n",
      "We are 48.4848% done\n",
      "We are 49.4949% done\n",
      "We are 50.5051% done\n",
      "We are 51.5152% done\n",
      "We are 52.5253% done\n",
      "We are 53.5354% done\n",
      "We are 54.5455% done\n",
      "We are 55.5556% done\n",
      "We are 56.5657% done\n",
      "We are 57.5758% done\n",
      "We are 58.5859% done\n",
      "We are 59.596% done\n",
      "We are 60.6061% done\n",
      "We are 61.6162% done\n",
      "We are 62.6263% done\n",
      "We are 63.6364% done\n",
      "We are 64.6465% done\n",
      "We are 65.6566% done\n",
      "We are 66.6667% done\n",
      "We are 67.6768% done\n",
      "We are 68.6869% done\n",
      "We are 69.697% done\n",
      "We are 70.7071% done\n",
      "We are 71.7172% done\n",
      "We are 72.7273% done\n",
      "We are 73.7374% done\n",
      "We are 74.7475% done\n",
      "We are 75.7576% done\n",
      "We are 76.7677% done\n",
      "We are 78.7879% done\n",
      "We are 80.8081% done\n",
      "We are 81.8182% done\n",
      "We are 82.8283% done\n",
      "We are 83.8384% done\n",
      "We are 84.8485% done\n",
      "We are 85.8586% done\n",
      "We are 86.8687% done\n",
      "We are 87.8788% done\n",
      "We are 88.8889% done\n",
      "We are 89.899% done\n",
      "We are 90.9091% done\n",
      "We are 91.9192% done\n",
      "We are 92.9293% done\n",
      "We are 93.9394% done\n",
      "We are 94.9495% done\n",
      "We are 95.9596% done\n",
      "We are 96.9697% done\n",
      "We are 97.9798% done\n",
      "We are 98.9899% done\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "genre = []\n",
    "write = []\n",
    "lyrics = []\n",
    "checker = {}\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    art = df.iloc[i][\"Artists\"]\n",
    "    name = df.iloc[i][\"Name\"]\n",
    "    \n",
    "    # haven't scraped the song lyrics yet\n",
    "    \n",
    "    if art + name not in checker:\n",
    "        try:\n",
    "            \n",
    "            temp = get_lyric_link(art, name)\n",
    "            checker.update({art + name: i})\n",
    "            d, g, w, l = scrape_lyrics(df.iloc[i], temp)\n",
    "            \n",
    "        except Exception:\n",
    "            \n",
    "            #rough hack to just skip for now\n",
    "            #that way we can view all the errors in one go!!\n",
    "            #i need to sleep...\n",
    "            #print(i)\n",
    "            #traceback.print_exc()\n",
    "            dates.append(\"\")\n",
    "            genre.append(\"\")\n",
    "            write.append(\"\")\n",
    "            lyrics.append(\"\")\n",
    "            continue\n",
    "            \n",
    "        dates.append(d)\n",
    "        genre.append(g)\n",
    "        write.append(w)\n",
    "        lyrics.append(l)\n",
    "    \n",
    "    # already scraped song lyrics\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        num = checker[art + name]\n",
    "        d, g, w, l = dates[num], genre[num], write[num], lyrics[num]\n",
    "        \n",
    "        dates.append(d)\n",
    "        genre.append(g)\n",
    "        write.append(w)\n",
    "        lyrics.append(l)        \n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(\"We are {}% done\".format(round(i / len(df) * 100, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06111111111111111"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(True for x in lyrics if x == \"\")/len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = dates\n",
    "df[\"Genre\"] = genre\n",
    "df[\"Writing Credits\"] = write\n",
    "df[\"Lyrics\"] = lyrics\n",
    "df.to_csv(\"..//..//data//Weekly_data.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[108]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug log:\n",
    " - Te Bote: accent error\n",
    " - Tiesto: accent error\n",
    " - Logic, Ryan Tedder: just checked hot links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_link = \"https://genius.com\"\n",
    "content = requests.get(base_link + \"/Nio-garcia-casper-magico-and-bad-bunny-te-bote-remix-lyrics\").content\n",
    "data = BeautifulSoup(content, \"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[97]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
