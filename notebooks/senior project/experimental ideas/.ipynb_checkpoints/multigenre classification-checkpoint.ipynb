{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"..//..//data//Weekly_data_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use the classification idea on five different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_distribution(d, type_ = \"train\"):\n",
    "    \"\"\"\n",
    "    if train: return word distribution\n",
    "    if test: return each testing example's word distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    from collections import Counter\n",
    "    from itertools import chain\n",
    "    \n",
    "    if type_ == \"train\":\n",
    "        ans = Counter(list(d))\n",
    "        norm = sum(ans.values())\n",
    "        for element in ans:\n",
    "            ans[element] /= norm\n",
    "            \n",
    "        impute = defaultdict(float)\n",
    "        for i in ans:\n",
    "            impute[i] = ans[i]\n",
    "        return impute\n",
    "\n",
    "    elif type_ == \"test\":\n",
    "        \n",
    "        ans = []\n",
    "        for song in d.ID.unique():\n",
    "            ans1 = Counter(list(d[d.ID == song].word))\n",
    "            norm = sum(ans1.values())\n",
    "            for element in ans1:\n",
    "                ans1[element] /= norm\n",
    "                \n",
    "            impute = defaultdict(float)\n",
    "            for i in ans1:\n",
    "                impute[i] = ans1[i]\n",
    "            ans.append(ans1)\n",
    "        return ans\n",
    "    \n",
    "def classify(data, dists, p_genre):\n",
    "    results = []\n",
    "    for song in data:\n",
    "        distance = {}\n",
    "        for dist in dists:\n",
    "            distance.update({dist: hellinger_distance(song, dists[dist])})\n",
    "        results.append(max(distance.items(), key = lambda x: x[1]))\n",
    "    return results\n",
    "\n",
    "def hellinger_distance(dist1, dist2):\n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "    for element in dist1.keys():\n",
    "        \n",
    "        num += (np.sqrt(dist1[element]) - np.sqrt(dist2[element])) ** 2\n",
    "        \n",
    "    num = (1 / np.sqrt(2)) * np.sqrt(num)\n",
    "    \n",
    "    return 1 - num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id's: 0: pop, 1: rap, 2: rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_type = []\n",
    "for word in range(len(df)):\n",
    "    if re.search(\"pop\", df.loc[word, \"Genre\"], flags = re.I) != None:\n",
    "        genre_type.append(0)\n",
    "    elif re.search(\"rap\", df.loc[word, \"Genre\"], flags = re.I) != None:\n",
    "        genre_type.append(1)\n",
    "    elif re.search(\"rock\", df.loc[word, \"Genre\"], flags = re.I) != None:\n",
    "        genre_type.append(2)      \n",
    "    elif re.search(\"country\", df.loc[word, \"Genre\"], flags = re.I) != None:\n",
    "        genre_type.append(3) \n",
    "    else:\n",
    "        genre_type.append(4)\n",
    "        \n",
    "df[\"genre_type\"] = genre_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 235838, 1: 258621, 2: 42204, 3: 34629, 4: 12366})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(genre_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a 65-35 split since we have 5 different classes now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = df.ID.unique()\n",
    "np.random.shuffle(IDs)\n",
    "train = df[df.ID.isin(IDs[:int(.65 * len(IDs))])]\n",
    "test = df[df.ID.isin(IDs[int(.65 * len(IDs)):])]\n",
    "\n",
    "poptrain = train[train[\"genre_type\"] == 0].word\n",
    "raptrain = train[train[\"genre_type\"] == 1].word\n",
    "rocktrain = train[train[\"genre_type\"] == 2].word\n",
    "countrytrain = train[train[\"genre_type\"] == 3].word\n",
    "othertrain = train[train[\"genre_type\"] == 4].word\n",
    "\n",
    "poptest = test[test[\"genre_type\"] == 0]\n",
    "raptest = test[test[\"genre_type\"] == 1]\n",
    "rocktest = test[test[\"genre_type\"] == 2]\n",
    "countrytest = test[test[\"genre_type\"] == 3]\n",
    "othertest = test[test[\"genre_type\"] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train.groupby(\"genre_type\")[\"ID\"].unique().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_genre = {\n",
    "    \"pop\": counts[0] / sum(counts),\n",
    "    \"rap\": counts[1] / sum(counts),\n",
    "    \"rock\": counts[2] / sum(counts),\n",
    "    \"country\": counts[3] / sum(counts),\n",
    "    \"other\": counts[4] / sum(counts),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "poptraindist = get_word_distribution(poptrain)\n",
    "raptraindist = get_word_distribution(raptrain)\n",
    "rocktraindist = get_word_distribution(rocktrain)\n",
    "countrytraindist = get_word_distribution(countrytrain)\n",
    "othertraindist = get_word_distribution(othertrain)\n",
    "\n",
    "\n",
    "dists = {\"pop\": poptraindist, \n",
    "         \"rap\": raptraindist,\n",
    "         \"rock\": rocktraindist,\n",
    "         \"country\": countrytraindist,\n",
    "         \"other\": othertraindist}\n",
    "\n",
    "poptestdist = get_word_distribution(poptest, \"test\")\n",
    "raptestdist = get_word_distribution(raptest, \"test\")\n",
    "rocktestdist = get_word_distribution(rocktest, \"test\")\n",
    "countrytestdist = get_word_distribution(countrytest, \"test\")\n",
    "othertestdist = get_word_distribution(othertest, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre_type\n",
       "0    1208\n",
       "1     732\n",
       "2     296\n",
       "3     226\n",
       "4      66\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops = [x[0] for x in classify(poptestdist, dists, p_genre)]\n",
    "raps = [x[0] for x in classify(raptestdist, dists, p_genre)]\n",
    "rocks = [x[0] for x in classify(rocktestdist, dists, p_genre)]\n",
    "countrys = [x[0] for x in classify(countrytestdist, dists, p_genre)]\n",
    "others = [x[0] for x in classify(othertestdist, dists, p_genre)]\n",
    "\n",
    "predicted = pops + raps + rocks + countrys + others\n",
    "\n",
    "true = [\"pop\" for _ in range(len(pops))] + \\\n",
    "       [\"rap\" for _ in range(len(raps))] + \\\n",
    "       [\"rock\" for _ in range(len(rocks))] + \\\n",
    "       [\"country\" for _ in range(len(countrys))] + \\\n",
    "       [\"other\" for _ in range(len(others))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = confusion_matrix(predicted, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5234948604992657"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.diag(ans)) / np.sum(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 79,   2,  94,  12,  64],\n",
       "       [  5,  10,  85,  11,   9],\n",
       "       [  4,  15, 230,  41,  29],\n",
       "       [  0,   4,  51, 334,   3],\n",
       "       [ 32,   3, 174,  11,  60]], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop': 230, 'other': 85, 'rock': 174, 'country': 94, 'rap': 51})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pop seems to be semi-easily confused w/ rock and country. Moreover, there is a non-trivial classification into rap. Definitely look into this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'rap': 334, 'pop': 41, 'other': 11, 'country': 12, 'rock': 11})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(raps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, rap is easily classified from the other genres. Consistent with our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop': 29, 'other': 9, 'rock': 60, 'country': 64, 'rap': 3})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(rocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rock music is easly misclassified as country. Definitely look into this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'country': 79, 'rock': 32, 'pop': 4, 'other': 5})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(countrys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Country music is easily classified as country; however, some are misclassified as rock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'pop': 15, 'rap': 4, 'other': 10, 'rock': 3, 'country': 2})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining genres are semi-easily confused with pop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
