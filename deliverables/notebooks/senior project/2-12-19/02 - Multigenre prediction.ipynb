{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: Multigenre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores various algorithms' ability to classify songs as pop, rap, rock or country. This notebook compares the same algorithms as the ones in Pop vs. Rap except we increase the number of genres to four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..//..//..//scripts\")\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import chain\n",
    "from NonParametricClassifier import *\n",
    "from CDFClassifier import *\n",
    "from HelperFunctions import *\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide which genres to add, we found the top four most popular genres. They are, in order, pop, rap, rock and country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pop', 1783),\n",
       " ('Rap', 1427),\n",
       " ('Rock', 721),\n",
       " ('Country', 692),\n",
       " ('R&;B', 661),\n",
       " ('Trap', 359),\n",
       " ('Canada', 266),\n",
       " ('Pop-Rock', 207)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"..//..//..//..//data//Weekly_data_tokenized.csv\")\n",
    "genre = []\n",
    "\n",
    "for unique in df.ID.unique():\n",
    "    genre.append(df[df.ID == unique].iloc[0].Genre)\n",
    "    \n",
    "genre = [x.split(\",\") for x in genre]\n",
    "genre = Counter(list(chain.from_iterable(genre)))\n",
    "genre = sorted(genre.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "genre[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the minimum Gini index is .125."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pop\"] = df.apply(lambda row: create_genre(row, \"pop\"), axis = 1)\n",
    "df[\"Rap\"] = df.apply(lambda row: create_genre(row, \"rap\"), axis = 1)\n",
    "df[\"Rock\"] = df.apply(lambda row: create_genre(row, \"rock\"), axis = 1)\n",
    "df[\"Country\"] = df.apply(lambda row: create_genre(row, \"country\"), axis = 1)\n",
    "\n",
    "df = df[[\"word\", \"ID\", \"Pop\", \"Rap\", \"Rock\", \"Country\"]]\n",
    "\n",
    "tmp = df.groupby([\"word\", \"Pop\", \"Rap\", \"Rock\", \"Country\"]).count().unstack().unstack().unstack().unstack().fillna(0)\n",
    "\n",
    "gini = calculate_gini_index(tmp)\n",
    "useless_words = [x for x in gini if gini[x] <= .236]\n",
    "\n",
    "df = df[~df.word.isin(useless_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove words with the bottom 3.2% of Gini indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033193979933110365"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(useless_words) / len(df.word.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we opted for a 80-20 split between the training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "IDs = df.ID.unique()\n",
    "np.random.shuffle(IDs)\n",
    "\n",
    "train = df[df.ID.isin(IDs[:int(.8 * len(IDs))])]\n",
    "test = df[df.ID.isin(IDs[int(.8 * len(IDs)):])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification by distribution comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An explanation of this algorithm is available in the notebook `01 - Pop vs. Rap Prediction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klgrid = grid_search_nonparametric(0.00000001, 0.0001, 200, NonParametricClassifier, train, test, [\"Pop\", \"Rap\", \"Rock\", \"Country\"], \"KL\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hellingergrid = grid_search_nonparametric(0, 5, 200, NonParametricClassifier, train, test, [\"Pop\", \"Rap\", \"Rock\", \"Country\"], \"hellinger\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_multigenre_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank-based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mann-Whitney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwgrid = grid_search_cdf(0.01, 2, 200, CDFClassifier, train, test, [\"Pop\", \"Rap\", \"Rock\", \"Country\"], \"Mann-Whitney\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to standard algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulligrid = {}\n",
    "grid2 = {}\n",
    "\n",
    "for n in np.linspace(0, 1, 200)[1:]:\n",
    "    clf = BernoulliNB(alpha = n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    bernoulligrid.update({n: confusion_matrix(clf.predict(X_test), y_test)})\n",
    "    grid2.update({n: np.diag(bernoulligrid[n]).sum() / bernoulligrid[n].sum()})\n",
    "    \n",
    "best = sorted(grid2.items(), key = lambda x: x[1], reverse = True)[0]\n",
    "print(\"Best accuracy:\", best[1])\n",
    "print(\"Parameter\", best[0])\n",
    "    \n",
    "plt.plot([i for i in grid2], [grid2[i] for i in grid2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multigrid = {}\n",
    "grid2 = {}\n",
    "\n",
    "for n in np.linspace(0, 1, 200)[1:]:\n",
    "    clf = MultinomialNB(alpha = n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    multigrid.update({n: confusion_matrix(clf.predict(X_test), y_test)})\n",
    "    grid2.update({n: np.diag(multigrid[n]).sum() / multigrid[n].sum()})\n",
    "    \n",
    "best = sorted(grid2.items(), key = lambda x: x[1], reverse = True)[0]\n",
    "print(\"Best accuracy:\", best[1])\n",
    "print(\"Parameter\", best[0])\n",
    "    \n",
    "plt.plot([i for i in grid2], [grid2[i] for i in grid2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = convert_genre(y_train)\n",
    "y_test_binary = convert_genre(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label = y_train_binary)\n",
    "dtest = xgb.DMatrix(X_test, label = y_test_binary)\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "grid = {}\n",
    "dims = 10\n",
    "\n",
    "for l1 in np.linspace(0, 1, dims):\n",
    "    for l2 in np.linspace(0, 1, dims):   \n",
    "        param = {'max_depth': 500, 'eta': 0.2, 'silent': 1, 'objective': 'multi:softprob', \"alpha\": l1,\n",
    "                 \"lambda\": l2, \"subsample\": 0.9, \"num_class\": 4, \"eval_metric\": \"mlogloss\", \"scale_pos_weight\": 1}\n",
    "        bst = xgb.train(params = param, dtrain = dtrain, num_boost_round = 200, evals = evallist, early_stopping_rounds = 20)\n",
    "        cfmat = confusion_matrix(np.argmax(bst.predict(dtest), 1), y_test_binary)\n",
    "        grid.update({(l1, l2): np.diag(cfmat).sum() / cfmat.sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((dims, dims))\n",
    "row = 0\n",
    "col = 0\n",
    "for (r, c) in grid:\n",
    "    mat[row, col] = grid[(r, c)]\n",
    "    col += 1\n",
    "    if (col) % dims == 0:\n",
    "        if (row, col) == (0, 1):\n",
    "            continue\n",
    "        col = 0\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(mat, annot = True, fmt = \".3f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow import Session, ConfigProto\n",
    "sess = Session(config=ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categories = \"auto\")\n",
    "enc.fit(y_train_binary.reshape((len(y_train_binary), 1)))\n",
    "y_train_onehot = enc.transform(y_train_binary.reshape((len(y_train_binary), 1))).toarray()\n",
    "y_test_onehot = enc.transform(y_test_binary.reshape((len(y_test_binary), 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = [\n",
    "    Dense(512, input_dim = 23920, activation = \"sigmoid\"),\n",
    "    Dense(128, activation = \"sigmoid\"),\n",
    "    Dense(32, activation = \"sigmoid\"),\n",
    "    Dense(8, activation = \"sigmoid\"),\n",
    "    Dense(4, activation = \"softmax\")\n",
    "]\n",
    "\n",
    "model = Sequential(arch)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = SGD(lr = 0.01),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "filepath = \"..//..//..//..//data//NN weights//weights-improvement-multigenre-{epoch:02d}-{val_categorical_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='categorical_accuracy',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    np.array(X_train), \n",
    "    np.array(y_train_onehot),\n",
    "    callbacks = callbacks_list,\n",
    "    verbose = 1, \n",
    "    epochs = 20,\n",
    "    batch_size = 2,\n",
    "    validation_data = [np.array(X_test), np.array(y_test_onehot)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(encoder, X, Y):\n",
    "    fig = plt.figure(figsize = (10, 6))\n",
    "    h = encoder.predict(np.array(X))\n",
    "    y_tester = np.array(Y)\n",
    "    for i in range(4):\n",
    "        sel = y_tester == i\n",
    "        plt.plot(h[sel, 0], h[sel, 1], '.', label='Group %d' % i, markersize = 3, alpha = 0.8)\n",
    "    plt.title('MLP embedding - test data')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, below is the embedding of our test data within our neural network. We can see that the neural network has learned a linearly separable representation of our frequency vectors. We also see that group 2 and 3 (Rock and Country) are very similar to group 0, or Pop. This implies that the text in pop, country, and rock are all very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = load_model(\"..//..//..//..//data//NN weights//weights-improvement-multigenre-10-0.5501.h5\")\n",
    "model_tmp = Sequential(nn.layers[:-1])\n",
    "plot_embedding(model_tmp, X_test, y_test_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Below is a table summarizing the performance of each algorithm on the validation set.\n",
    "\n",
    "\n",
    "| KL    | Hellinger | Mann-Whitney | NB-Bernoulli | NB-Multinomial | xgboost | Neural network |\n",
    "|:-----:|:---------:|:------------:|---|---|---|:---:|\n",
    "|0.8262|  0.84   |    0.769    |<b>0.85538|0.82769|0.846|0.8277|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
